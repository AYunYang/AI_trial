{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc4ce40e-d027-4e27-bf59-c1e7e679c701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2438 entries, 0 to 2437\n",
      "Data columns (total 69 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   Datetime                      2438 non-null   datetime64[ns]\n",
      " 1   FC_Unit_1_Status              2438 non-null   object        \n",
      " 2   FC_Unit_1_Fan_Status          2438 non-null   object        \n",
      " 3   FC_Unit_1_Set_Point           2438 non-null   float64       \n",
      " 4   FC_Unit_1_Operation_Mode      2438 non-null   object        \n",
      " 5   FC_Unit_2_Status              2438 non-null   object        \n",
      " 6   FC_Unit_2_Fan_Status          2438 non-null   object        \n",
      " 7   FC_Unit_2_Set_Point           2438 non-null   float64       \n",
      " 8   FC_Unit_2_Operation_Mode      2438 non-null   object        \n",
      " 9   FC_Unit_3_Status              2438 non-null   object        \n",
      " 10  FC_Unit_3_Fan_Status          2438 non-null   object        \n",
      " 11  FC_Unit_3_Set_Point           2438 non-null   float64       \n",
      " 12  FC_Unit_3_Operation_Mode      2438 non-null   object        \n",
      " 13  FC_Unit_4_Status              2438 non-null   object        \n",
      " 14  FC_Unit_4_Fan_Status          2438 non-null   object        \n",
      " 15  FC_Unit_4_Set_Point           2438 non-null   float64       \n",
      " 16  FC_Unit_4_Operation_Mode      2438 non-null   object        \n",
      " 17  FC_Unit_5_Status              2438 non-null   object        \n",
      " 18  FC_Unit_5_Fan_Status          2438 non-null   object        \n",
      " 19  FC_Unit_5_Set_Point           2438 non-null   float64       \n",
      " 20  FC_Unit_5_Operation_Mode      2438 non-null   object        \n",
      " 21  FC_Unit_6_Status              2438 non-null   object        \n",
      " 22  FC_Unit_6_Fan_Status          2438 non-null   object        \n",
      " 23  FC_Unit_6_Set_Point           2438 non-null   float64       \n",
      " 24  FC_Unit_6_Operation_Mode      2438 non-null   object        \n",
      " 25  FC_Unit_7_Status              2438 non-null   object        \n",
      " 26  FC_Unit_7_Fan_Status          2438 non-null   object        \n",
      " 27  FC_Unit_7_Set_Point           2438 non-null   float64       \n",
      " 28  FC_Unit_7_Operation_Mode      2438 non-null   object        \n",
      " 29  FC_Unit_8_Status              2438 non-null   object        \n",
      " 30  FC_Unit_8_Fan_Status          2438 non-null   object        \n",
      " 31  FC_Unit_8_Set_Point           2438 non-null   float64       \n",
      " 32  FC_Unit_8_Operation_Mode      2438 non-null   object        \n",
      " 33  Sensor_1_Current              2438 non-null   float64       \n",
      " 34  Sensor_1_Energy               2438 non-null   float64       \n",
      " 35  Sensor_1_Power                2438 non-null   float64       \n",
      " 36  Sensor_3_Current              2438 non-null   float64       \n",
      " 37  Sensor_3_Energy               2438 non-null   float64       \n",
      " 38  Sensor_3_Power                2438 non-null   float64       \n",
      " 39  Sensor_6_Current              2438 non-null   float64       \n",
      " 40  Sensor_6_Energy               2438 non-null   float64       \n",
      " 41  Sensor_6_Power                2438 non-null   float64       \n",
      " 42  24E124725E331695_Humidity     2438 non-null   float64       \n",
      " 43  24E124725E331695_Temperature  2438 non-null   float64       \n",
      " 44  24E124725E331744_Humidity     2438 non-null   float64       \n",
      " 45  24E124725E331744_Temperature  2438 non-null   float64       \n",
      " 46  24E124725E332483_Humidity     2438 non-null   float64       \n",
      " 47  24E124725E332483_Temperature  2438 non-null   float64       \n",
      " 48  24E124725E331733_Humidity     2438 non-null   float64       \n",
      " 49  24E124725E331733_Temperature  2438 non-null   float64       \n",
      " 50  24E124725E290348_Humidity     2438 non-null   float64       \n",
      " 51  24E124725E290348_Temperature  2438 non-null   float64       \n",
      " 52  24E124725E286745_Humidity     2438 non-null   float64       \n",
      " 53  24E124725E286745_Temperature  2438 non-null   float64       \n",
      " 54  24E124725E286745_CO2          2438 non-null   float64       \n",
      " 55  24E124725E285123_Humidity     2438 non-null   float64       \n",
      " 56  24E124725E285123_Temperature  2438 non-null   float64       \n",
      " 57  24E124725E285123_CO2          2438 non-null   float64       \n",
      " 58  weather_status                2438 non-null   object        \n",
      " 59  weather_temp                  2438 non-null   float64       \n",
      " 60  weather_humid                 2438 non-null   int64         \n",
      " 61  total_energy                  2438 non-null   float64       \n",
      " 62  total_power                   2438 non-null   float64       \n",
      " 63  total_current                 2438 non-null   float64       \n",
      " 64  avg_temperature               2438 non-null   float64       \n",
      " 65  avg_humidity                  2438 non-null   float64       \n",
      " 66  avg_co2                       2438 non-null   float64       \n",
      " 67  hour                          2438 non-null   int32         \n",
      " 68  Day_of_week                   2438 non-null   int32         \n",
      "dtypes: datetime64[ns](1), float64(40), int32(2), int64(1), object(25)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "Sensor_readings = pd.read_json('data/json/W512.w512_readings (1).json')\n",
    "Aircon_Data = pd.read_json('data/json/W512.w512_aircon_status (1).json')\n",
    "Weather_readings = pd.read_json('data/json/user.weather_data (1).json')\n",
    "\n",
    "def convert_AirconData(data):\n",
    "    records = []\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        # Parse FC_FullStatus_Readings if it's a string representation of a dictionary\n",
    "        if isinstance(row['FC_FullStatus_Readings'], str):\n",
    "            fc_readings = ast.literal_eval(row['FC_FullStatus_Readings'])\n",
    "        else:\n",
    "            fc_readings = row['FC_FullStatus_Readings']\n",
    "\n",
    "\n",
    "        try:\n",
    "            combined_datetime = pd.to_datetime(f\"{row['date']} {row['time']}\")\n",
    "            formatted_datetime = pd.to_datetime(combined_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error combining datetime for row {index}: {e}\")\n",
    "            combined_datetime = None\n",
    "            formatted_datetime = None\n",
    "\n",
    "        \n",
    "        # Create a record with base information\n",
    "        record = {\n",
    "            'Datetime': formatted_datetime\n",
    "        }\n",
    "        \n",
    "        # Add each FC Unit's details as separate columns\n",
    "        for unit, unit_data in fc_readings.items():\n",
    "            record[f'{unit}_Status'] = unit_data['Status']\n",
    "            record[f'{unit}_Fan_Status'] = unit_data['Fan_Status']\n",
    "            record[f'{unit}_Set_Point'] = unit_data['Set_Point']\n",
    "            record[f'{unit}_Operation_Mode'] = unit_data['Operation_Mode']\n",
    "        \n",
    "        records.append(record)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_sensorReadings(data):\n",
    "    records = []\n",
    "    \n",
    "    # List of keys to exclude from Lorawan_Readings\n",
    "    include_keys_1 = [\"24E124725E285123\", \"24E124725E331695\",\"24E124725E331744\",\n",
    "                      \"24E124725E332483\",\"24E124725E290348\",\"24E124725E331733\",\"24E124725E286745\"]#\"24E124136D316361\" is suppiosed to be outdoor but it is not outdoor yet\n",
    "    include_keys_2 = [\"Sensor_1\",\"Sensor_3\",\"Sensor_6\"]\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        # Parse Energy_Readings if it's a string representation of a dictionary\n",
    "        if isinstance(row['Energy_Readings'], str):\n",
    "            Energy_readings = ast.literal_eval(row['Energy_Readings'])\n",
    "        else:\n",
    "            Energy_readings = row['Energy_Readings']\n",
    "            \n",
    "        # Parse Lorawan_Readings if it's a string representation of a dictionary\n",
    "        if isinstance(row['Lorawan_Readings'], str):\n",
    "            Lorawan_Readings = ast.literal_eval(row['Lorawan_Readings'])\n",
    "        else:\n",
    "            Lorawan_Readings = row['Lorawan_Readings']\n",
    "\n",
    "        try:\n",
    "            # Combine the date and time columns to create a datetime object\n",
    "            combined_datetime = pd.to_datetime(f\"{row['date']} {row['time']}\")\n",
    "            formatted_datetime = pd.to_datetime(combined_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error combining datetime for row {index}: {e}\")\n",
    "            formatted_datetime = None\n",
    "\n",
    "        # Create a record with base information\n",
    "        record = {\n",
    "            'Datetime': formatted_datetime\n",
    "        }\n",
    "        \n",
    "        # Add each Energy sensor's details as separate columns\n",
    "        for unit, unit_data in Energy_readings.items():\n",
    "            if unit not in include_keys_2:\n",
    "                continue\n",
    "                \n",
    "            record[f'{unit}_Current'] = unit_data['Current']\n",
    "            record[f'{unit}_Energy'] = unit_data['Energy']\n",
    "            record[f'{unit}_Power'] = unit_data['Power']\n",
    "        \n",
    "        # Add each Lorawan device's details as separate columns\n",
    "        for unit, unit_data in Lorawan_Readings.items():\n",
    "            if unit not in include_keys_1:\n",
    "                continue\n",
    "            record[f'{unit}_Humidity'] = unit_data.get('humidity', None)\n",
    "            record[f'{unit}_Temperature'] = unit_data.get('temperature', None)\n",
    "\n",
    "            co2_value = unit_data.get('co2', None)\n",
    "            if co2_value is not None:\n",
    "                record[f'{unit}_CO2'] = co2_value\n",
    "\n",
    "        # Append the record to the list of records\n",
    "        records.append(record)\n",
    "    df=pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_weatherData(data):\n",
    "    records = []\n",
    "    for index, row in data.iterrows():\n",
    "        # Parse Energy_Readings if it's a string representation of a dictionary\n",
    "        if isinstance(row['result'], str):\n",
    "            weather_results = ast.literal_eval(row['result'])\n",
    "        else:\n",
    "            weather_results = row['result']\n",
    "            \n",
    "        try:\n",
    "            combined_datetime = pd.to_datetime(f\"{row['date']} {row['time']}\")\n",
    "            formatted_datetime = pd.to_datetime(combined_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error combining datetime for row {index}: {e}\")\n",
    "            formatted_datetime = None\n",
    "\n",
    "        record = {\n",
    "            'Datetime': formatted_datetime\n",
    "        }  \n",
    "\n",
    "        record['weather_status'] = weather_results['weather_status']\n",
    "        record['weather_temp'] = weather_results['weather_temp']\n",
    "        record['weather_humid'] = weather_results['weather_humidity']\n",
    "            \n",
    "        records.append(record)\n",
    "    df=pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "Aircon_data_df = convert_AirconData(Aircon_Data)\n",
    "Aircon_data_df = Aircon_data_df[3194:]\n",
    "Sensor_readings_df = convert_sensorReadings(Sensor_readings)\n",
    "Sensor_readings_df = Sensor_readings_df.interpolate(method='linear')\n",
    "weather_readings_df = convert_weatherData(Weather_readings)\n",
    "\n",
    "# Merge Aircon data with Sensor readings using merge_asof\n",
    "merged_df = pd.merge_asof(Aircon_data_df, Sensor_readings_df, on='Datetime', direction='nearest')\n",
    "\n",
    "# Now, merge the Weather readings with the previous result using merge_asof\n",
    "merged_df = pd.merge_asof(merged_df, weather_readings_df, on='Datetime', direction='nearest')\n",
    "\n",
    "\n",
    "merged_df['total_energy'] = (\n",
    "    merged_df['Sensor_1_Energy'] +\n",
    "    merged_df['Sensor_3_Energy'] +\n",
    "    merged_df['Sensor_6_Energy']\n",
    ")\n",
    "\n",
    "merged_df['total_power'] = (\n",
    "    merged_df['Sensor_1_Power'] +\n",
    "    merged_df['Sensor_3_Power'] +\n",
    "    merged_df['Sensor_6_Power']\n",
    ")\n",
    "\n",
    "merged_df['total_current'] = (\n",
    "    merged_df['Sensor_1_Current'] +\n",
    "    merged_df['Sensor_3_Current'] +\n",
    "    merged_df['Sensor_6_Current']\n",
    ")\n",
    "\n",
    "temperature_col = [\n",
    "    col for col in merged_df.columns \n",
    "    if \"24e124\" in col.lower() and \"temperature\" in col.lower()\n",
    "]\n",
    "humidity_col = [\n",
    "    col for col in merged_df.columns \n",
    "    if \"24e124\" in col.lower() and \"humidity\" in col.lower()\n",
    "]\n",
    "co2_col = [\n",
    "    col for col in merged_df.columns \n",
    "    if \"24e124\" in col.lower() and \"co2\" in col.lower()\n",
    "]\n",
    "\n",
    "merged_df['avg_temperature'] = merged_df[temperature_col].mean(axis=1)\n",
    "merged_df['avg_humidity'] = merged_df[humidity_col].mean(axis=1)\n",
    "merged_df['avg_co2'] = merged_df[co2_col].mean(axis=1)\n",
    "\n",
    "merged_df['hour'] = pd.to_datetime(merged_df['Datetime']).dt.hour\n",
    "merged_df['Day_of_week'] = pd.to_datetime(merged_df['Datetime']).dt.dayofweek\n",
    "\n",
    "merged_df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df641a8b-76ef-4b0c-9ac4-6a9d0d963e26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from hyperparam_tuning\\fanunit_LSTM_1\\tuner0.json\n",
      "Best Hyperparameters:\n",
      "{'units_lstm': 96, 'l2_lstm': 0.054, 'return_sequences': True, 'dropout_lstm': 0.0, 'units_dense': 64, 'l2_dense': 0.001, 'learning_rate': 0.001}\n",
      "Epoch 1/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.9846 - mae: 0.3108 - val_loss: 0.1676 - val_mae: 0.1700\n",
      "Epoch 2/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1425 - mae: 0.1587 - val_loss: 0.1429 - val_mae: 0.1545\n",
      "Epoch 3/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1290 - mae: 0.1480 - val_loss: 0.1360 - val_mae: 0.1480\n",
      "Epoch 4/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1218 - mae: 0.1439 - val_loss: 0.1216 - val_mae: 0.1381\n",
      "Epoch 5/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1199 - mae: 0.1400 - val_loss: 0.1119 - val_mae: 0.1320\n",
      "Epoch 6/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1014 - mae: 0.1276 - val_loss: 0.1073 - val_mae: 0.1298\n",
      "Epoch 7/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1037 - mae: 0.1276 - val_loss: 0.1039 - val_mae: 0.1294\n",
      "Epoch 8/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0951 - mae: 0.1223 - val_loss: 0.1000 - val_mae: 0.1251\n",
      "Epoch 9/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0989 - mae: 0.1226 - val_loss: 0.0987 - val_mae: 0.1259\n",
      "Epoch 10/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0943 - mae: 0.1205 - val_loss: 0.0954 - val_mae: 0.1203\n",
      "Epoch 11/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0962 - mae: 0.1204 - val_loss: 0.0958 - val_mae: 0.1239\n",
      "Epoch 12/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0958 - mae: 0.1193 - val_loss: 0.0935 - val_mae: 0.1153\n",
      "Epoch 13/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0894 - mae: 0.1155 - val_loss: 0.0920 - val_mae: 0.1183\n",
      "Epoch 14/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0885 - mae: 0.1156 - val_loss: 0.0903 - val_mae: 0.1144\n",
      "Epoch 15/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0867 - mae: 0.1140 - val_loss: 0.0900 - val_mae: 0.1134\n",
      "Epoch 16/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0875 - mae: 0.1100 - val_loss: 0.0886 - val_mae: 0.1104\n",
      "Epoch 17/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0831 - mae: 0.1113 - val_loss: 0.0871 - val_mae: 0.1088\n",
      "Epoch 18/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0806 - mae: 0.1042 - val_loss: 0.0861 - val_mae: 0.1094\n",
      "Epoch 19/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0804 - mae: 0.1071 - val_loss: 0.0857 - val_mae: 0.1105\n",
      "Epoch 20/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0795 - mae: 0.1074 - val_loss: 0.0843 - val_mae: 0.1080\n",
      "Epoch 21/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0801 - mae: 0.1074 - val_loss: 0.0836 - val_mae: 0.1062\n",
      "Epoch 22/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0812 - mae: 0.1058 - val_loss: 0.0831 - val_mae: 0.1074\n",
      "Epoch 23/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0810 - mae: 0.1049 - val_loss: 0.0828 - val_mae: 0.1061\n",
      "Epoch 24/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0758 - mae: 0.1023 - val_loss: 0.0818 - val_mae: 0.1043\n",
      "Epoch 25/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0785 - mae: 0.1016 - val_loss: 0.0811 - val_mae: 0.1026\n",
      "Epoch 26/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0802 - mae: 0.1030 - val_loss: 0.0819 - val_mae: 0.1036\n",
      "Epoch 27/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0757 - mae: 0.1015 - val_loss: 0.0805 - val_mae: 0.1038\n",
      "Epoch 28/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0909 - mae: 0.1104 - val_loss: 0.0808 - val_mae: 0.1034\n",
      "Epoch 29/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0706 - mae: 0.0998 - val_loss: 0.0794 - val_mae: 0.0995\n",
      "Epoch 30/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0786 - mae: 0.1005 - val_loss: 0.0800 - val_mae: 0.1052\n",
      "Epoch 31/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0751 - mae: 0.1006 - val_loss: 0.0791 - val_mae: 0.1018\n",
      "Epoch 32/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0707 - mae: 0.0955 - val_loss: 0.0787 - val_mae: 0.1053\n",
      "Epoch 33/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0696 - mae: 0.0973 - val_loss: 0.0781 - val_mae: 0.1010\n",
      "Epoch 34/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0709 - mae: 0.0970 - val_loss: 0.0783 - val_mae: 0.1024\n",
      "Epoch 35/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0713 - mae: 0.0979 - val_loss: 0.0774 - val_mae: 0.1011\n",
      "Epoch 36/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0718 - mae: 0.0976 - val_loss: 0.0785 - val_mae: 0.1015\n",
      "Epoch 37/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0698 - mae: 0.0964 - val_loss: 0.0795 - val_mae: 0.1032\n",
      "Epoch 38/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0710 - mae: 0.0964 - val_loss: 0.0768 - val_mae: 0.1006\n",
      "Epoch 39/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0759 - mae: 0.0992 - val_loss: 0.0768 - val_mae: 0.0999\n",
      "Epoch 40/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0711 - mae: 0.1001 - val_loss: 0.0770 - val_mae: 0.1010\n",
      "Epoch 41/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0676 - mae: 0.0943 - val_loss: 0.0769 - val_mae: 0.1022\n",
      "Epoch 42/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0705 - mae: 0.0951 - val_loss: 0.0768 - val_mae: 0.1021\n",
      "Epoch 43/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0681 - mae: 0.0961 - val_loss: 0.0764 - val_mae: 0.1007\n",
      "Epoch 44/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0756 - mae: 0.1008 - val_loss: 0.0751 - val_mae: 0.0993\n",
      "Epoch 45/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0705 - mae: 0.0966 - val_loss: 0.0756 - val_mae: 0.0976\n",
      "Epoch 46/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0664 - mae: 0.0933 - val_loss: 0.0749 - val_mae: 0.0978\n",
      "Epoch 47/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0699 - mae: 0.0971 - val_loss: 0.0754 - val_mae: 0.0980\n",
      "Epoch 48/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0649 - mae: 0.0915 - val_loss: 0.0747 - val_mae: 0.0975\n",
      "Epoch 49/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0700 - mae: 0.0961 - val_loss: 0.0760 - val_mae: 0.0965\n",
      "Epoch 50/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0733 - mae: 0.0999 - val_loss: 0.0742 - val_mae: 0.0962\n",
      "Epoch 51/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0671 - mae: 0.0909 - val_loss: 0.0739 - val_mae: 0.0961\n",
      "Epoch 52/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0681 - mae: 0.0925 - val_loss: 0.0752 - val_mae: 0.0990\n",
      "Epoch 53/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0664 - mae: 0.0917 - val_loss: 0.0737 - val_mae: 0.1005\n",
      "Epoch 54/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0702 - mae: 0.0961 - val_loss: 0.0735 - val_mae: 0.0963\n",
      "Epoch 55/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0658 - mae: 0.0893 - val_loss: 0.0739 - val_mae: 0.0981\n",
      "Epoch 56/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0663 - mae: 0.0960 - val_loss: 0.0727 - val_mae: 0.0955\n",
      "Epoch 57/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0692 - mae: 0.0962 - val_loss: 0.0738 - val_mae: 0.0989\n",
      "Epoch 58/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0633 - mae: 0.0901 - val_loss: 0.0728 - val_mae: 0.0966\n",
      "Epoch 59/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0687 - mae: 0.0946 - val_loss: 0.0726 - val_mae: 0.0968\n",
      "Epoch 60/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0671 - mae: 0.0929 - val_loss: 0.0722 - val_mae: 0.0956\n",
      "Epoch 61/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0736 - mae: 0.0994 - val_loss: 0.0727 - val_mae: 0.0987\n",
      "Epoch 62/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0656 - mae: 0.0953 - val_loss: 0.0722 - val_mae: 0.0966\n",
      "Epoch 63/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0705 - mae: 0.0941 - val_loss: 0.0725 - val_mae: 0.0978\n",
      "Epoch 64/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0708 - mae: 0.0983 - val_loss: 0.0724 - val_mae: 0.0971\n",
      "Epoch 65/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0697 - mae: 0.0954 - val_loss: 0.0718 - val_mae: 0.0957\n",
      "Epoch 66/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0665 - mae: 0.0938 - val_loss: 0.0714 - val_mae: 0.0932\n",
      "Epoch 67/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0626 - mae: 0.0899 - val_loss: 0.0720 - val_mae: 0.0984\n",
      "Epoch 68/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0693 - mae: 0.0937 - val_loss: 0.0716 - val_mae: 0.0944\n",
      "Epoch 69/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0669 - mae: 0.0906 - val_loss: 0.0713 - val_mae: 0.0931\n",
      "Epoch 70/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0649 - mae: 0.0883 - val_loss: 0.0716 - val_mae: 0.0961\n",
      "Epoch 71/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0677 - mae: 0.0923 - val_loss: 0.0712 - val_mae: 0.0937\n",
      "Epoch 72/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0656 - mae: 0.0891 - val_loss: 0.0723 - val_mae: 0.0978\n",
      "Epoch 73/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0671 - mae: 0.0945 - val_loss: 0.0708 - val_mae: 0.0933\n",
      "Epoch 74/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0690 - mae: 0.0919 - val_loss: 0.0712 - val_mae: 0.0963\n",
      "Epoch 75/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0656 - mae: 0.0902 - val_loss: 0.0724 - val_mae: 0.0963\n",
      "Epoch 76/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0630 - mae: 0.0906 - val_loss: 0.0703 - val_mae: 0.0947\n",
      "Epoch 77/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0617 - mae: 0.0862 - val_loss: 0.0708 - val_mae: 0.0947\n",
      "Epoch 78/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0673 - mae: 0.0937 - val_loss: 0.0705 - val_mae: 0.0963\n",
      "Epoch 79/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0709 - mae: 0.0952 - val_loss: 0.0699 - val_mae: 0.0941\n",
      "Epoch 80/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0648 - mae: 0.0901 - val_loss: 0.0695 - val_mae: 0.0935\n",
      "Epoch 81/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0642 - mae: 0.0934 - val_loss: 0.0695 - val_mae: 0.0921\n",
      "Epoch 82/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0669 - mae: 0.0920 - val_loss: 0.0712 - val_mae: 0.0953\n",
      "Epoch 83/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0623 - mae: 0.0895 - val_loss: 0.0699 - val_mae: 0.0934\n",
      "Epoch 84/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0638 - mae: 0.0909 - val_loss: 0.0693 - val_mae: 0.0918\n",
      "Epoch 85/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0653 - mae: 0.0902 - val_loss: 0.0694 - val_mae: 0.0928\n",
      "Epoch 86/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0684 - mae: 0.0938 - val_loss: 0.0697 - val_mae: 0.0927\n",
      "Epoch 87/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0603 - mae: 0.0867 - val_loss: 0.0691 - val_mae: 0.0908\n",
      "Epoch 88/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0680 - mae: 0.0906 - val_loss: 0.0700 - val_mae: 0.0941\n",
      "Epoch 89/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0647 - mae: 0.0914 - val_loss: 0.0685 - val_mae: 0.0920\n",
      "Epoch 90/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0623 - mae: 0.0873 - val_loss: 0.0688 - val_mae: 0.0926\n",
      "Epoch 91/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0638 - mae: 0.0899 - val_loss: 0.0690 - val_mae: 0.0912\n",
      "Epoch 92/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0672 - mae: 0.0911 - val_loss: 0.0694 - val_mae: 0.0919\n",
      "Epoch 93/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0630 - mae: 0.0883 - val_loss: 0.0710 - val_mae: 0.0950\n",
      "Epoch 94/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0688 - mae: 0.0943 - val_loss: 0.0683 - val_mae: 0.0893\n",
      "Epoch 95/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0634 - mae: 0.0898 - val_loss: 0.0689 - val_mae: 0.0914\n",
      "Epoch 96/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0623 - mae: 0.0872 - val_loss: 0.0699 - val_mae: 0.0916\n",
      "Epoch 97/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0635 - mae: 0.0888 - val_loss: 0.0685 - val_mae: 0.0937\n",
      "Epoch 98/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0694 - mae: 0.0925 - val_loss: 0.0682 - val_mae: 0.0899\n",
      "Epoch 99/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0662 - mae: 0.0905 - val_loss: 0.0690 - val_mae: 0.0928\n",
      "Epoch 100/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0662 - mae: 0.0929 - val_loss: 0.0688 - val_mae: 0.0924\n",
      "Epoch 101/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0626 - mae: 0.0885 - val_loss: 0.0680 - val_mae: 0.0904\n",
      "Epoch 102/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0620 - mae: 0.0866 - val_loss: 0.0681 - val_mae: 0.0923\n",
      "Epoch 103/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0620 - mae: 0.0866 - val_loss: 0.0677 - val_mae: 0.0918\n",
      "Epoch 104/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0610 - mae: 0.0881 - val_loss: 0.0680 - val_mae: 0.0935\n",
      "Epoch 105/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0646 - mae: 0.0915 - val_loss: 0.0677 - val_mae: 0.0902\n",
      "Epoch 106/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0593 - mae: 0.0853 - val_loss: 0.0671 - val_mae: 0.0916\n",
      "Epoch 107/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0628 - mae: 0.0869 - val_loss: 0.0672 - val_mae: 0.0906\n",
      "Epoch 108/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0630 - mae: 0.0873 - val_loss: 0.0677 - val_mae: 0.0911\n",
      "Epoch 109/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0544 - mae: 0.0825 - val_loss: 0.0699 - val_mae: 0.0956\n",
      "Epoch 110/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0633 - mae: 0.0899 - val_loss: 0.0666 - val_mae: 0.0894\n",
      "Epoch 111/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0649 - mae: 0.0899 - val_loss: 0.0671 - val_mae: 0.0880\n",
      "Epoch 112/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0639 - mae: 0.0875 - val_loss: 0.0667 - val_mae: 0.0899\n",
      "Epoch 113/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0661 - mae: 0.0919 - val_loss: 0.0670 - val_mae: 0.0881\n",
      "Epoch 114/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0622 - mae: 0.0876 - val_loss: 0.0679 - val_mae: 0.0930\n",
      "Epoch 115/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0628 - mae: 0.0868 - val_loss: 0.0667 - val_mae: 0.0891\n",
      "Epoch 116/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0604 - mae: 0.0853 - val_loss: 0.0669 - val_mae: 0.0888\n",
      "Epoch 117/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0617 - mae: 0.0881 - val_loss: 0.0667 - val_mae: 0.0895\n",
      "Epoch 118/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0643 - mae: 0.0899 - val_loss: 0.0664 - val_mae: 0.0894\n",
      "Epoch 119/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0631 - mae: 0.0902 - val_loss: 0.0660 - val_mae: 0.0888\n",
      "Epoch 120/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0598 - mae: 0.0842 - val_loss: 0.0659 - val_mae: 0.0898\n",
      "Epoch 121/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0598 - mae: 0.0871 - val_loss: 0.0675 - val_mae: 0.0945\n",
      "Epoch 122/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0602 - mae: 0.0858 - val_loss: 0.0662 - val_mae: 0.0906\n",
      "Epoch 123/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0674 - mae: 0.0940 - val_loss: 0.0657 - val_mae: 0.0870\n",
      "Epoch 124/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0601 - mae: 0.0874 - val_loss: 0.0656 - val_mae: 0.0872\n",
      "Epoch 125/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0665 - mae: 0.0915 - val_loss: 0.0656 - val_mae: 0.0892\n",
      "Epoch 126/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0595 - mae: 0.0852 - val_loss: 0.0663 - val_mae: 0.0918\n",
      "Epoch 127/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0642 - mae: 0.0901 - val_loss: 0.0656 - val_mae: 0.0882\n",
      "Epoch 128/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0611 - mae: 0.0872 - val_loss: 0.0664 - val_mae: 0.0873\n",
      "Epoch 129/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0628 - mae: 0.0877 - val_loss: 0.0655 - val_mae: 0.0869\n",
      "Epoch 130/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0618 - mae: 0.0864 - val_loss: 0.0662 - val_mae: 0.0910\n",
      "Epoch 131/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0619 - mae: 0.0888 - val_loss: 0.0658 - val_mae: 0.0888\n",
      "Epoch 132/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0598 - mae: 0.0835 - val_loss: 0.0666 - val_mae: 0.0897\n",
      "Epoch 133/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0644 - mae: 0.0917 - val_loss: 0.0656 - val_mae: 0.0889\n",
      "Epoch 134/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0555 - mae: 0.0826 - val_loss: 0.0651 - val_mae: 0.0882\n",
      "Epoch 135/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0566 - mae: 0.0830 - val_loss: 0.0650 - val_mae: 0.0893\n",
      "Epoch 136/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0624 - mae: 0.0863 - val_loss: 0.0652 - val_mae: 0.0880\n",
      "Epoch 137/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0622 - mae: 0.0876 - val_loss: 0.0659 - val_mae: 0.0880\n",
      "Epoch 138/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0583 - mae: 0.0846 - val_loss: 0.0645 - val_mae: 0.0853\n",
      "Epoch 139/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0616 - mae: 0.0840 - val_loss: 0.0652 - val_mae: 0.0909\n",
      "Epoch 140/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0560 - mae: 0.0825 - val_loss: 0.0650 - val_mae: 0.0912\n",
      "Epoch 141/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0587 - mae: 0.0862 - val_loss: 0.0643 - val_mae: 0.0856\n",
      "Epoch 142/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0585 - mae: 0.0837 - val_loss: 0.0643 - val_mae: 0.0911\n",
      "Epoch 143/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0662 - mae: 0.0903 - val_loss: 0.0639 - val_mae: 0.0853\n",
      "Epoch 144/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0532 - mae: 0.0802 - val_loss: 0.0640 - val_mae: 0.0887\n",
      "Epoch 145/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0638 - mae: 0.0854 - val_loss: 0.0654 - val_mae: 0.0869\n",
      "Epoch 146/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0645 - mae: 0.0857 - val_loss: 0.0636 - val_mae: 0.0836\n",
      "Epoch 147/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0620 - mae: 0.0854 - val_loss: 0.0632 - val_mae: 0.0833\n",
      "Epoch 148/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0657 - mae: 0.0890 - val_loss: 0.0642 - val_mae: 0.0865\n",
      "Epoch 149/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0584 - mae: 0.0845 - val_loss: 0.0635 - val_mae: 0.0855\n",
      "Epoch 150/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0577 - mae: 0.0832 - val_loss: 0.0629 - val_mae: 0.0844\n",
      "Epoch 151/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0603 - mae: 0.0840 - val_loss: 0.0633 - val_mae: 0.0847\n",
      "Epoch 152/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0681 - mae: 0.0893 - val_loss: 0.0627 - val_mae: 0.0836\n",
      "Epoch 153/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0535 - mae: 0.0782 - val_loss: 0.0626 - val_mae: 0.0852\n",
      "Epoch 154/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0576 - mae: 0.0802 - val_loss: 0.0629 - val_mae: 0.0860\n",
      "Epoch 155/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0639 - mae: 0.0841 - val_loss: 0.0644 - val_mae: 0.0877\n",
      "Epoch 156/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0591 - mae: 0.0824 - val_loss: 0.0643 - val_mae: 0.0868\n",
      "Epoch 157/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0610 - mae: 0.0842 - val_loss: 0.0634 - val_mae: 0.0877\n",
      "Epoch 158/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0587 - mae: 0.0834 - val_loss: 0.0628 - val_mae: 0.0857\n",
      "Epoch 159/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0612 - mae: 0.0871 - val_loss: 0.0624 - val_mae: 0.0839\n",
      "Epoch 160/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0609 - mae: 0.0849 - val_loss: 0.0625 - val_mae: 0.0830\n",
      "Epoch 161/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0549 - mae: 0.0797 - val_loss: 0.0628 - val_mae: 0.0840\n",
      "Epoch 162/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0616 - mae: 0.0875 - val_loss: 0.0616 - val_mae: 0.0812\n",
      "Epoch 163/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0526 - mae: 0.0775 - val_loss: 0.0627 - val_mae: 0.0860\n",
      "Epoch 164/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0584 - mae: 0.0825 - val_loss: 0.0618 - val_mae: 0.0814\n",
      "Epoch 165/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0644 - mae: 0.0859 - val_loss: 0.0629 - val_mae: 0.0847\n",
      "Epoch 166/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0517 - mae: 0.0769 - val_loss: 0.0613 - val_mae: 0.0851\n",
      "Epoch 167/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0572 - mae: 0.0832 - val_loss: 0.0621 - val_mae: 0.0815\n",
      "Epoch 168/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0555 - mae: 0.0785 - val_loss: 0.0621 - val_mae: 0.0865\n",
      "Epoch 169/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0606 - mae: 0.0831 - val_loss: 0.0626 - val_mae: 0.0858\n",
      "Epoch 170/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0553 - mae: 0.0806 - val_loss: 0.0614 - val_mae: 0.0807\n",
      "Epoch 171/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0563 - mae: 0.0799 - val_loss: 0.0611 - val_mae: 0.0810\n",
      "Epoch 172/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0571 - mae: 0.0811 - val_loss: 0.0616 - val_mae: 0.0834\n",
      "Epoch 173/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0567 - mae: 0.0797 - val_loss: 0.0612 - val_mae: 0.0822\n",
      "Epoch 174/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0630 - mae: 0.0855 - val_loss: 0.0629 - val_mae: 0.0839\n",
      "Epoch 175/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0526 - mae: 0.0798 - val_loss: 0.0611 - val_mae: 0.0855\n",
      "Epoch 176/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0575 - mae: 0.0812 - val_loss: 0.0612 - val_mae: 0.0821\n",
      "Epoch 177/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0599 - mae: 0.0822 - val_loss: 0.0603 - val_mae: 0.0787\n",
      "Epoch 178/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0528 - mae: 0.0766 - val_loss: 0.0611 - val_mae: 0.0816\n",
      "Epoch 179/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0558 - mae: 0.0808 - val_loss: 0.0608 - val_mae: 0.0831\n",
      "Epoch 180/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0553 - mae: 0.0812 - val_loss: 0.0618 - val_mae: 0.0821\n",
      "Epoch 181/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0533 - mae: 0.0769 - val_loss: 0.0626 - val_mae: 0.0855\n",
      "Epoch 182/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0579 - mae: 0.0806 - val_loss: 0.0601 - val_mae: 0.0827\n",
      "Epoch 183/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0564 - mae: 0.0775 - val_loss: 0.0611 - val_mae: 0.0839\n",
      "Epoch 184/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0584 - mae: 0.0783 - val_loss: 0.0603 - val_mae: 0.0807\n",
      "Epoch 185/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0528 - mae: 0.0788 - val_loss: 0.0608 - val_mae: 0.0815\n",
      "Epoch 186/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0572 - mae: 0.0804 - val_loss: 0.0605 - val_mae: 0.0790\n",
      "Epoch 187/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0546 - mae: 0.0776 - val_loss: 0.0601 - val_mae: 0.0803\n",
      "Epoch 188/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0568 - mae: 0.0803 - val_loss: 0.0602 - val_mae: 0.0802\n",
      "Epoch 189/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0524 - mae: 0.0761 - val_loss: 0.0604 - val_mae: 0.0799\n",
      "Epoch 190/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0516 - mae: 0.0760 - val_loss: 0.0611 - val_mae: 0.0841\n",
      "Epoch 191/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0524 - mae: 0.0770 - val_loss: 0.0593 - val_mae: 0.0785\n",
      "Epoch 192/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0600 - mae: 0.0801 - val_loss: 0.0596 - val_mae: 0.0796\n",
      "Epoch 193/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0554 - mae: 0.0761 - val_loss: 0.0599 - val_mae: 0.0806\n",
      "Epoch 194/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0574 - mae: 0.0783 - val_loss: 0.0598 - val_mae: 0.0793\n",
      "Epoch 195/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0542 - mae: 0.0773 - val_loss: 0.0602 - val_mae: 0.0788\n",
      "Epoch 196/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0555 - mae: 0.0768 - val_loss: 0.0610 - val_mae: 0.0813\n",
      "Epoch 197/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0585 - mae: 0.0783 - val_loss: 0.0604 - val_mae: 0.0840\n",
      "Epoch 198/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0577 - mae: 0.0810 - val_loss: 0.0585 - val_mae: 0.0776\n",
      "Epoch 199/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0520 - mae: 0.0751 - val_loss: 0.0589 - val_mae: 0.0776\n",
      "Epoch 200/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0528 - mae: 0.0745 - val_loss: 0.0589 - val_mae: 0.0819\n",
      "Epoch 201/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0559 - mae: 0.0777 - val_loss: 0.0586 - val_mae: 0.0792\n",
      "Epoch 202/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0551 - mae: 0.0773 - val_loss: 0.0600 - val_mae: 0.0802\n",
      "Epoch 203/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0541 - mae: 0.0758 - val_loss: 0.0584 - val_mae: 0.0776\n",
      "Epoch 204/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0519 - mae: 0.0750 - val_loss: 0.0587 - val_mae: 0.0788\n",
      "Epoch 205/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0534 - mae: 0.0778 - val_loss: 0.0592 - val_mae: 0.0781\n",
      "Epoch 206/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0490 - mae: 0.0741 - val_loss: 0.0584 - val_mae: 0.0781\n",
      "Epoch 207/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0576 - mae: 0.0806 - val_loss: 0.0595 - val_mae: 0.0794\n",
      "Epoch 208/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0514 - mae: 0.0745 - val_loss: 0.0585 - val_mae: 0.0791\n",
      "Epoch 209/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0543 - mae: 0.0761 - val_loss: 0.0586 - val_mae: 0.0758\n",
      "Epoch 210/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0524 - mae: 0.0723 - val_loss: 0.0573 - val_mae: 0.0749\n",
      "Epoch 211/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0535 - mae: 0.0771 - val_loss: 0.0576 - val_mae: 0.0757\n",
      "Epoch 212/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0542 - mae: 0.0780 - val_loss: 0.0571 - val_mae: 0.0743\n",
      "Epoch 213/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0525 - mae: 0.0735 - val_loss: 0.0587 - val_mae: 0.0780\n",
      "Epoch 214/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0551 - mae: 0.0756 - val_loss: 0.0577 - val_mae: 0.0789\n",
      "Epoch 215/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0534 - mae: 0.0769 - val_loss: 0.0579 - val_mae: 0.0779\n",
      "Epoch 216/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0509 - mae: 0.0725 - val_loss: 0.0581 - val_mae: 0.0768\n",
      "Epoch 217/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0532 - mae: 0.0747 - val_loss: 0.0596 - val_mae: 0.0787\n",
      "Epoch 218/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0504 - mae: 0.0741 - val_loss: 0.0578 - val_mae: 0.0749\n",
      "Epoch 219/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0535 - mae: 0.0755 - val_loss: 0.0572 - val_mae: 0.0757\n",
      "Epoch 220/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0521 - mae: 0.0744 - val_loss: 0.0573 - val_mae: 0.0765\n",
      "Epoch 221/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0540 - mae: 0.0781 - val_loss: 0.0568 - val_mae: 0.0745\n",
      "Epoch 222/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0546 - mae: 0.0746 - val_loss: 0.0574 - val_mae: 0.0765\n",
      "Epoch 223/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0568 - mae: 0.0760 - val_loss: 0.0566 - val_mae: 0.0746\n",
      "Epoch 224/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0549 - mae: 0.0758 - val_loss: 0.0571 - val_mae: 0.0763\n",
      "Epoch 225/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0515 - mae: 0.0728 - val_loss: 0.0598 - val_mae: 0.0798\n",
      "Epoch 226/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0542 - mae: 0.0759 - val_loss: 0.0565 - val_mae: 0.0763\n",
      "Epoch 227/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0516 - mae: 0.0734 - val_loss: 0.0572 - val_mae: 0.0792\n",
      "Epoch 228/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0525 - mae: 0.0737 - val_loss: 0.0565 - val_mae: 0.0748\n",
      "Epoch 229/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0515 - mae: 0.0742 - val_loss: 0.0564 - val_mae: 0.0753\n",
      "Epoch 230/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0518 - mae: 0.0749 - val_loss: 0.0578 - val_mae: 0.0754\n",
      "Epoch 231/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0520 - mae: 0.0730 - val_loss: 0.0565 - val_mae: 0.0749\n",
      "Epoch 232/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0536 - mae: 0.0744 - val_loss: 0.0563 - val_mae: 0.0746\n",
      "Epoch 233/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0517 - mae: 0.0742 - val_loss: 0.0573 - val_mae: 0.0775\n",
      "Epoch 234/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0535 - mae: 0.0738 - val_loss: 0.0563 - val_mae: 0.0737\n",
      "Epoch 235/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0500 - mae: 0.0728 - val_loss: 0.0562 - val_mae: 0.0748\n",
      "Epoch 236/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0500 - mae: 0.0717 - val_loss: 0.0579 - val_mae: 0.0797\n",
      "Epoch 237/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0527 - mae: 0.0736 - val_loss: 0.0557 - val_mae: 0.0737\n",
      "Epoch 238/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0481 - mae: 0.0724 - val_loss: 0.0556 - val_mae: 0.0757\n",
      "Epoch 239/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0519 - mae: 0.0725 - val_loss: 0.0563 - val_mae: 0.0777\n",
      "Epoch 240/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0493 - mae: 0.0710 - val_loss: 0.0558 - val_mae: 0.0769\n",
      "Epoch 241/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0496 - mae: 0.0718 - val_loss: 0.0563 - val_mae: 0.0757\n",
      "Epoch 242/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0528 - mae: 0.0727 - val_loss: 0.0559 - val_mae: 0.0760\n",
      "Epoch 243/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0516 - mae: 0.0727 - val_loss: 0.0565 - val_mae: 0.0749\n",
      "Epoch 244/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0510 - mae: 0.0739 - val_loss: 0.0558 - val_mae: 0.0746\n",
      "Epoch 245/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0550 - mae: 0.0762 - val_loss: 0.0558 - val_mae: 0.0732\n",
      "Epoch 246/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0510 - mae: 0.0722 - val_loss: 0.0583 - val_mae: 0.0761\n",
      "Epoch 247/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0512 - mae: 0.0724 - val_loss: 0.0567 - val_mae: 0.0739\n",
      "Epoch 248/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0539 - mae: 0.0740 - val_loss: 0.0548 - val_mae: 0.0725\n",
      "Epoch 249/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0495 - mae: 0.0717 - val_loss: 0.0556 - val_mae: 0.0725\n",
      "Epoch 250/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0492 - mae: 0.0727 - val_loss: 0.0554 - val_mae: 0.0755\n",
      "Epoch 251/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0509 - mae: 0.0746 - val_loss: 0.0551 - val_mae: 0.0738\n",
      "Epoch 252/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0503 - mae: 0.0721 - val_loss: 0.0557 - val_mae: 0.0734\n",
      "Epoch 253/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0558 - mae: 0.0784 - val_loss: 0.0553 - val_mae: 0.0740\n",
      "Epoch 254/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0513 - mae: 0.0731 - val_loss: 0.0549 - val_mae: 0.0758\n",
      "Epoch 255/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0508 - mae: 0.0737 - val_loss: 0.0550 - val_mae: 0.0712\n",
      "Epoch 256/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0476 - mae: 0.0700 - val_loss: 0.0542 - val_mae: 0.0725\n",
      "Epoch 257/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0504 - mae: 0.0721 - val_loss: 0.0546 - val_mae: 0.0722\n",
      "Epoch 258/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0492 - mae: 0.0711 - val_loss: 0.0564 - val_mae: 0.0749\n",
      "Epoch 259/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0486 - mae: 0.0703 - val_loss: 0.0542 - val_mae: 0.0726\n",
      "Epoch 260/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0478 - mae: 0.0705 - val_loss: 0.0547 - val_mae: 0.0710\n",
      "Epoch 261/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0563 - mae: 0.0773 - val_loss: 0.0542 - val_mae: 0.0710\n",
      "Epoch 262/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0493 - mae: 0.0720 - val_loss: 0.0544 - val_mae: 0.0738\n",
      "Epoch 263/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0453 - mae: 0.0688 - val_loss: 0.0550 - val_mae: 0.0727\n",
      "Epoch 264/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0468 - mae: 0.0690 - val_loss: 0.0537 - val_mae: 0.0703\n",
      "Epoch 265/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0507 - mae: 0.0736 - val_loss: 0.0571 - val_mae: 0.0821\n",
      "Epoch 266/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0525 - mae: 0.0750 - val_loss: 0.0544 - val_mae: 0.0712\n",
      "Epoch 267/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0526 - mae: 0.0730 - val_loss: 0.0550 - val_mae: 0.0745\n",
      "Epoch 268/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0531 - mae: 0.0745 - val_loss: 0.0549 - val_mae: 0.0749\n",
      "Epoch 269/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0506 - mae: 0.0707 - val_loss: 0.0540 - val_mae: 0.0718\n",
      "Epoch 270/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0478 - mae: 0.0707 - val_loss: 0.0549 - val_mae: 0.0764\n",
      "Epoch 271/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0516 - mae: 0.0744 - val_loss: 0.0549 - val_mae: 0.0712\n",
      "Epoch 272/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0458 - mae: 0.0694 - val_loss: 0.0546 - val_mae: 0.0725\n",
      "Epoch 273/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0520 - mae: 0.0745 - val_loss: 0.0535 - val_mae: 0.0715\n",
      "Epoch 274/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0475 - mae: 0.0694 - val_loss: 0.0544 - val_mae: 0.0745\n",
      "Epoch 275/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0503 - mae: 0.0722 - val_loss: 0.0532 - val_mae: 0.0702\n",
      "Epoch 276/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0496 - mae: 0.0709 - val_loss: 0.0538 - val_mae: 0.0704\n",
      "Epoch 277/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0478 - mae: 0.0702 - val_loss: 0.0539 - val_mae: 0.0715\n",
      "Epoch 278/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0509 - mae: 0.0728 - val_loss: 0.0536 - val_mae: 0.0704\n",
      "Epoch 279/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0501 - mae: 0.0707 - val_loss: 0.0535 - val_mae: 0.0720\n",
      "Epoch 280/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0476 - mae: 0.0719 - val_loss: 0.0541 - val_mae: 0.0712\n",
      "Epoch 281/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0508 - mae: 0.0729 - val_loss: 0.0535 - val_mae: 0.0700\n",
      "Epoch 282/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0495 - mae: 0.0718 - val_loss: 0.0535 - val_mae: 0.0728\n",
      "Epoch 283/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0518 - mae: 0.0749 - val_loss: 0.0531 - val_mae: 0.0718\n",
      "Epoch 284/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0505 - mae: 0.0723 - val_loss: 0.0535 - val_mae: 0.0727\n",
      "Epoch 285/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0461 - mae: 0.0685 - val_loss: 0.0533 - val_mae: 0.0723\n",
      "Epoch 286/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0507 - mae: 0.0721 - val_loss: 0.0542 - val_mae: 0.0722\n",
      "Epoch 287/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0456 - mae: 0.0687 - val_loss: 0.0549 - val_mae: 0.0738\n",
      "Epoch 288/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0477 - mae: 0.0717 - val_loss: 0.0557 - val_mae: 0.0764\n",
      "Epoch 289/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0464 - mae: 0.0689 - val_loss: 0.0530 - val_mae: 0.0718\n",
      "Epoch 290/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0515 - mae: 0.0738 - val_loss: 0.0528 - val_mae: 0.0717\n",
      "Epoch 291/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0444 - mae: 0.0684 - val_loss: 0.0549 - val_mae: 0.0752\n",
      "Epoch 292/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0491 - mae: 0.0721 - val_loss: 0.0539 - val_mae: 0.0688\n",
      "Epoch 293/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0470 - mae: 0.0684 - val_loss: 0.0560 - val_mae: 0.0742\n",
      "Epoch 294/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0496 - mae: 0.0739 - val_loss: 0.0530 - val_mae: 0.0709\n",
      "Epoch 295/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0473 - mae: 0.0683 - val_loss: 0.0535 - val_mae: 0.0721\n",
      "Epoch 296/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0526 - mae: 0.0726 - val_loss: 0.0538 - val_mae: 0.0725\n",
      "Epoch 297/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0449 - mae: 0.0667 - val_loss: 0.0524 - val_mae: 0.0692\n",
      "Epoch 298/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0478 - mae: 0.0686 - val_loss: 0.0533 - val_mae: 0.0698\n",
      "Epoch 299/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0467 - mae: 0.0691 - val_loss: 0.0531 - val_mae: 0.0725\n",
      "Epoch 300/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0484 - mae: 0.0691 - val_loss: 0.0530 - val_mae: 0.0710\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.optimizers import Adam\\\n",
    "\n",
    "# Input and categorical features\n",
    "input_features = [\n",
    "    'avg_temperature', 'avg_humidity', 'avg_co2',\n",
    "    'weather_temp', 'weather_humid', 'total_energy',\n",
    "    'total_power', 'total_current', 'hour', 'Day_of_week'\n",
    "]\n",
    "cat_features = ['weather_status']\n",
    "\n",
    "# Fan unit columns\n",
    "fan_unit_col = [col for col in merged_df.columns if \"fc_unit\" in col.lower()]\n",
    "\n",
    "# Split X and y\n",
    "X = merged_df[input_features + cat_features]\n",
    "y = merged_df[fan_unit_col]\n",
    "\n",
    "# Preprocessor for X\n",
    "preprocessor_X = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), input_features),\n",
    "        ('cat', OneHotEncoder(), cat_features)\n",
    "    ]\n",
    ")\n",
    "X_processed = preprocessor_X.fit_transform(X)\n",
    "\n",
    "# Preprocessor for y\n",
    "cat_cols = [col for col in fan_unit_col if \"Status\" in col or \"Mode\" in col]\n",
    "num_cols = [col for col in fan_unit_col if \"Set_Point\" in col]\n",
    "preprocessor_y = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), cat_cols),\n",
    "        ('num', StandardScaler(), num_cols)\n",
    "    ]\n",
    ")\n",
    "y_processed = preprocessor_y.fit_transform(y)\n",
    "\n",
    "# Ensure y_processed is dense\n",
    "if hasattr(y_processed, \"toarray\"):\n",
    "    y_processed = y_processed.toarray()\n",
    "\n",
    "# Reshape X and y for LSTM\n",
    "X_processed = X_processed.reshape((X_processed.shape[0], 1, X_processed.shape[1]))\n",
    "y_processed = y_processed.reshape((y_processed.shape[0], 1, y_processed.shape[1]))\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y_processed, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Define the LSTM model-building function for KerasTuner\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # LSTM layer\n",
    "    model.add(LSTM(\n",
    "        units=hp.Int('units_lstm', min_value=32, max_value=128, step=32),\n",
    "        activation='tanh',\n",
    "        recurrent_activation='sigmoid',\n",
    "        kernel_regularizer=l2(hp.Float('l2_lstm', 0.001, 0.1, step=0.001)),\n",
    "        input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "        return_sequences=hp.Boolean('return_sequences')\n",
    "    ))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_lstm', 0.0, 0.5, step=0.1)))\n",
    "\n",
    "    # Dense layers\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units_dense', min_value=16, max_value=64, step=16),\n",
    "        activation='relu',\n",
    "        kernel_regularizer=l2(hp.Float('l2_dense', 0.001, 0.1, step=0.001))\n",
    "    ))\n",
    "\n",
    "    # Output layer (multi-output)\n",
    "    model.add(Dense(y_train.shape[2], activation='linear'))\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = Adam(learning_rate=hp.Choice('learning_rate', values=[1e-3, 1e-4]))   \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize KerasTuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    directory='hyperparam_tuning',\n",
    "    project_name='fanunit_LSTM_1'\n",
    ")\n",
    "\n",
    "# Callback for early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Perform hyperparameter search\n",
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    epochs=300,\n",
    "    validation_split=0.3,\n",
    "    batch_size=8,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_hps.values)\n",
    "\n",
    "# Build and train the model with best hyperparameters\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.3,\n",
    "    epochs=300,\n",
    "    batch_size=8,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "best_model.save('models/LSTM_Fanunit_v1.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c3f144c-86b0-48e6-aff7-9baa4ac72f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scenario 1 Conditions:\n",
      "ISO_formatted_datetime: 2024-12-12T15:17:45.818313\n",
      "avg_temperature: 28.42\n",
      "avg_humidity: 33.19\n",
      "avg_co2: 461.11\n",
      "weather_temp: 26.58\n",
      "weather_humidity: 62.78\n",
      "total_current: 1.31\n",
      "total_energy: 4657.14\n",
      "total_power: 12.31\n",
      "hour: 7\n",
      "day_of_week: 5\n",
      "weather_status: Thunderstorm\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([current_conditions])\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Preprocess\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m X_temp \u001b[38;5;241m=\u001b[39m preprocessor_X\u001b[38;5;241m.\u001b[39mtransform(df[input_features \u001b[38;5;241m+\u001b[39m categorical_features])\n\u001b[0;32m     69\u001b[0m X_temp \u001b[38;5;241m=\u001b[39m X_temp\u001b[38;5;241m.\u001b[39mreshape((X_temp\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, X_temp\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1035\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform X separately by each transformer, concatenate results.\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \n\u001b[0;32m   1011\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;124;03m    sparse matrices.\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m _raise_for_params(params, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1035\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1036\u001b[0m X \u001b[38;5;241m=\u001b[39m _check_X(X)\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m# If ColumnTransformer is fit using a dataframe, and now a dataframe is\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m# passed to be transformed, we select columns by name instead. This\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;66;03m# enables the user to pass X at transform time with extra columns which\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;66;03m# were not present in fit time, and the order of the columns doesn't\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;66;03m# matter.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1661\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Or ignore specific warning types\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "# List of possible weather statuses\n",
    "weather_statuses = ['Clouds', 'Rain', 'Thunderstorm']\n",
    "\n",
    "# Relevant columns for input\n",
    "input_features = [\n",
    "    'avg_temperature', 'avg_humidity', 'avg_co2',\n",
    "    'weather_temp', 'weather_humidity', 'total_energy', \n",
    "    'total_power', 'total_current', 'hour', 'day_of_week'\n",
    "]\n",
    "categorical_features = ['weather_status']\n",
    "\n",
    "\n",
    "def generate_random_conditions():\n",
    "    \"\"\"Generate a dictionary of randomized conditions\"\"\"\n",
    "    return {\n",
    "        'ISO_formatted_datetime': datetime.now().isoformat(),\n",
    "        'avg_temperature': round(random.uniform(20, 30), 2),\n",
    "        'avg_humidity': round(random.uniform(30, 80), 2),\n",
    "        'avg_co2': round(random.uniform(350, 500), 2),\n",
    "        'weather_temp': round(random.uniform(22, 33), 2),\n",
    "        'weather_humidity': round(random.uniform(40, 90), 2),\n",
    "        'total_current': round(random.uniform(0.5, 1.5), 2),\n",
    "        'total_energy': round(random.uniform(2000, 5000), 2),\n",
    "        'total_power': round(random.uniform(5, 15), 2),\n",
    "        'hour': random.randint(0, 23), \n",
    "        'day_of_week': random.randint(0, 6),  \n",
    "        'weather_status': random.choice(weather_statuses)\n",
    "    }\n",
    "\n",
    "# Generate multiple random condition sets\n",
    "num_scenarios = 5\n",
    "scenario_results = []\n",
    "\n",
    "loaded_model = keras.models.load_model(\"models/LSTM_Fanunit_v1.keras\")\n",
    "\n",
    "for scenario in range(num_scenarios):\n",
    "    # Generate a random set of conditions\n",
    "    current_conditions = generate_random_conditions()\n",
    "    print(f\"\\nScenario {scenario + 1} Conditions:\")\n",
    "    for key, value in current_conditions.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Create a DataFrame with the current conditions\n",
    "    df = pd.DataFrame([current_conditions])\n",
    "    \n",
    "    # Preprocess\n",
    "    X_temp = preprocessor.transform(df[input_features + categorical_features])\n",
    "    X_temp = X_temp.reshape((X_temp.shape[0], 1, X_temp.shape[1]))\n",
    "    \n",
    "    # Predict\n",
    "    prediction = loaded_model.predict(X_temp)[0][0]\n",
    "    \n",
    "    # Print prediction\n",
    "    print(f\"\\nPredicted Optimal Temperature: {float(prediction):.2f}°C\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f75b5-2ac9-4475-8b77-1d4d5f602195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
