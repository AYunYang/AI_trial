{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4ce40e-d027-4e27-bf59-c1e7e679c701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2438 entries, 0 to 2437\n",
      "Data columns (total 69 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   Datetime                      2438 non-null   datetime64[ns]\n",
      " 1   FC_Unit_1_Status              2438 non-null   object        \n",
      " 2   FC_Unit_1_Fan_Status          2438 non-null   object        \n",
      " 3   FC_Unit_1_Set_Point           2438 non-null   float64       \n",
      " 4   FC_Unit_1_Operation_Mode      2438 non-null   object        \n",
      " 5   FC_Unit_2_Status              2438 non-null   object        \n",
      " 6   FC_Unit_2_Fan_Status          2438 non-null   object        \n",
      " 7   FC_Unit_2_Set_Point           2438 non-null   float64       \n",
      " 8   FC_Unit_2_Operation_Mode      2438 non-null   object        \n",
      " 9   FC_Unit_3_Status              2438 non-null   object        \n",
      " 10  FC_Unit_3_Fan_Status          2438 non-null   object        \n",
      " 11  FC_Unit_3_Set_Point           2438 non-null   float64       \n",
      " 12  FC_Unit_3_Operation_Mode      2438 non-null   object        \n",
      " 13  FC_Unit_4_Status              2438 non-null   object        \n",
      " 14  FC_Unit_4_Fan_Status          2438 non-null   object        \n",
      " 15  FC_Unit_4_Set_Point           2438 non-null   float64       \n",
      " 16  FC_Unit_4_Operation_Mode      2438 non-null   object        \n",
      " 17  FC_Unit_5_Status              2438 non-null   object        \n",
      " 18  FC_Unit_5_Fan_Status          2438 non-null   object        \n",
      " 19  FC_Unit_5_Set_Point           2438 non-null   float64       \n",
      " 20  FC_Unit_5_Operation_Mode      2438 non-null   object        \n",
      " 21  FC_Unit_6_Status              2438 non-null   object        \n",
      " 22  FC_Unit_6_Fan_Status          2438 non-null   object        \n",
      " 23  FC_Unit_6_Set_Point           2438 non-null   float64       \n",
      " 24  FC_Unit_6_Operation_Mode      2438 non-null   object        \n",
      " 25  FC_Unit_7_Status              2438 non-null   object        \n",
      " 26  FC_Unit_7_Fan_Status          2438 non-null   object        \n",
      " 27  FC_Unit_7_Set_Point           2438 non-null   float64       \n",
      " 28  FC_Unit_7_Operation_Mode      2438 non-null   object        \n",
      " 29  FC_Unit_8_Status              2438 non-null   object        \n",
      " 30  FC_Unit_8_Fan_Status          2438 non-null   object        \n",
      " 31  FC_Unit_8_Set_Point           2438 non-null   float64       \n",
      " 32  FC_Unit_8_Operation_Mode      2438 non-null   object        \n",
      " 33  Sensor_1_Current              2438 non-null   float64       \n",
      " 34  Sensor_1_Energy               2438 non-null   float64       \n",
      " 35  Sensor_1_Power                2438 non-null   float64       \n",
      " 36  Sensor_3_Current              2438 non-null   float64       \n",
      " 37  Sensor_3_Energy               2438 non-null   float64       \n",
      " 38  Sensor_3_Power                2438 non-null   float64       \n",
      " 39  Sensor_6_Current              2438 non-null   float64       \n",
      " 40  Sensor_6_Energy               2438 non-null   float64       \n",
      " 41  Sensor_6_Power                2438 non-null   float64       \n",
      " 42  24E124725E331695_Humidity     2438 non-null   float64       \n",
      " 43  24E124725E331695_Temperature  2438 non-null   float64       \n",
      " 44  24E124725E331744_Humidity     2438 non-null   float64       \n",
      " 45  24E124725E331744_Temperature  2438 non-null   float64       \n",
      " 46  24E124725E332483_Humidity     2438 non-null   float64       \n",
      " 47  24E124725E332483_Temperature  2438 non-null   float64       \n",
      " 48  24E124725E331733_Humidity     2438 non-null   float64       \n",
      " 49  24E124725E331733_Temperature  2438 non-null   float64       \n",
      " 50  24E124725E290348_Humidity     2438 non-null   float64       \n",
      " 51  24E124725E290348_Temperature  2438 non-null   float64       \n",
      " 52  24E124725E286745_Humidity     2438 non-null   float64       \n",
      " 53  24E124725E286745_Temperature  2438 non-null   float64       \n",
      " 54  24E124725E286745_CO2          2438 non-null   float64       \n",
      " 55  24E124725E285123_Humidity     2438 non-null   float64       \n",
      " 56  24E124725E285123_Temperature  2438 non-null   float64       \n",
      " 57  24E124725E285123_CO2          2438 non-null   float64       \n",
      " 58  weather_status                2438 non-null   object        \n",
      " 59  weather_temp                  2438 non-null   float64       \n",
      " 60  weather_humid                 2438 non-null   int64         \n",
      " 61  total_energy                  2438 non-null   float64       \n",
      " 62  total_power                   2438 non-null   float64       \n",
      " 63  total_current                 2438 non-null   float64       \n",
      " 64  avg_temperature               2438 non-null   float64       \n",
      " 65  avg_humidity                  2438 non-null   float64       \n",
      " 66  avg_co2                       2438 non-null   float64       \n",
      " 67  hour                          2438 non-null   int32         \n",
      " 68  Day_of_week                   2438 non-null   int32         \n",
      "dtypes: datetime64[ns](1), float64(40), int32(2), int64(1), object(25)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "Sensor_readings = pd.read_json('data/json/W512.w512_readings (1).json')\n",
    "Aircon_Data = pd.read_json('data/json/W512.w512_aircon_status (1).json')\n",
    "Weather_readings = pd.read_json('data/json/user.weather_data (1).json')\n",
    "\n",
    "def convert_AirconData(data):\n",
    "    records = []\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        # Parse FC_FullStatus_Readings if it's a string representation of a dictionary\n",
    "        if isinstance(row['FC_FullStatus_Readings'], str):\n",
    "            fc_readings = ast.literal_eval(row['FC_FullStatus_Readings'])\n",
    "        else:\n",
    "            fc_readings = row['FC_FullStatus_Readings']\n",
    "\n",
    "\n",
    "        try:\n",
    "            combined_datetime = pd.to_datetime(f\"{row['date']} {row['time']}\")\n",
    "            formatted_datetime = pd.to_datetime(combined_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error combining datetime for row {index}: {e}\")\n",
    "            combined_datetime = None\n",
    "            formatted_datetime = None\n",
    "\n",
    "        \n",
    "        # Create a record with base information\n",
    "        record = {\n",
    "            'Datetime': formatted_datetime\n",
    "        }\n",
    "        \n",
    "        # Add each FC Unit's details as separate columns\n",
    "        for unit, unit_data in fc_readings.items():\n",
    "            record[f'{unit}_Status'] = unit_data['Status']\n",
    "            record[f'{unit}_Fan_Status'] = unit_data['Fan_Status']\n",
    "            record[f'{unit}_Set_Point'] = unit_data['Set_Point']\n",
    "            record[f'{unit}_Operation_Mode'] = unit_data['Operation_Mode']\n",
    "        \n",
    "        records.append(record)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_sensorReadings(data):\n",
    "    records = []\n",
    "    \n",
    "    # List of keys to exclude from Lorawan_Readings\n",
    "    include_keys_1 = [\"24E124725E285123\", \"24E124725E331695\",\"24E124725E331744\",\n",
    "                      \"24E124725E332483\",\"24E124725E290348\",\"24E124725E331733\",\"24E124725E286745\"]#\"24E124136D316361\" is suppiosed to be outdoor but it is not outdoor yet\n",
    "    include_keys_2 = [\"Sensor_1\",\"Sensor_3\",\"Sensor_6\"]\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        # Parse Energy_Readings if it's a string representation of a dictionary\n",
    "        if isinstance(row['Energy_Readings'], str):\n",
    "            Energy_readings = ast.literal_eval(row['Energy_Readings'])\n",
    "        else:\n",
    "            Energy_readings = row['Energy_Readings']\n",
    "            \n",
    "        # Parse Lorawan_Readings if it's a string representation of a dictionary\n",
    "        if isinstance(row['Lorawan_Readings'], str):\n",
    "            Lorawan_Readings = ast.literal_eval(row['Lorawan_Readings'])\n",
    "        else:\n",
    "            Lorawan_Readings = row['Lorawan_Readings']\n",
    "\n",
    "        try:\n",
    "            # Combine the date and time columns to create a datetime object\n",
    "            combined_datetime = pd.to_datetime(f\"{row['date']} {row['time']}\")\n",
    "            formatted_datetime = pd.to_datetime(combined_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error combining datetime for row {index}: {e}\")\n",
    "            formatted_datetime = None\n",
    "\n",
    "        # Create a record with base information\n",
    "        record = {\n",
    "            'Datetime': formatted_datetime\n",
    "        }\n",
    "        \n",
    "        # Add each Energy sensor's details as separate columns\n",
    "        for unit, unit_data in Energy_readings.items():\n",
    "            if unit not in include_keys_2:\n",
    "                continue\n",
    "                \n",
    "            record[f'{unit}_Current'] = unit_data['Current']\n",
    "            record[f'{unit}_Energy'] = unit_data['Energy']\n",
    "            record[f'{unit}_Power'] = unit_data['Power']\n",
    "        \n",
    "        # Add each Lorawan device's details as separate columns\n",
    "        for unit, unit_data in Lorawan_Readings.items():\n",
    "            if unit not in include_keys_1:\n",
    "                continue\n",
    "            record[f'{unit}_Humidity'] = unit_data.get('humidity', None)\n",
    "            record[f'{unit}_Temperature'] = unit_data.get('temperature', None)\n",
    "\n",
    "            co2_value = unit_data.get('co2', None)\n",
    "            if co2_value is not None:\n",
    "                record[f'{unit}_CO2'] = co2_value\n",
    "\n",
    "        # Append the record to the list of records\n",
    "        records.append(record)\n",
    "    df=pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_weatherData(data):\n",
    "    records = []\n",
    "    for index, row in data.iterrows():\n",
    "        # Parse Energy_Readings if it's a string representation of a dictionary\n",
    "        if isinstance(row['result'], str):\n",
    "            weather_results = ast.literal_eval(row['result'])\n",
    "        else:\n",
    "            weather_results = row['result']\n",
    "            \n",
    "        try:\n",
    "            combined_datetime = pd.to_datetime(f\"{row['date']} {row['time']}\")\n",
    "            formatted_datetime = pd.to_datetime(combined_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error combining datetime for row {index}: {e}\")\n",
    "            formatted_datetime = None\n",
    "\n",
    "        record = {\n",
    "            'Datetime': formatted_datetime\n",
    "        }  \n",
    "\n",
    "        record['weather_status'] = weather_results['weather_status']\n",
    "        record['weather_temp'] = weather_results['weather_temp']\n",
    "        record['weather_humid'] = weather_results['weather_humidity']\n",
    "            \n",
    "        records.append(record)\n",
    "    df=pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "Aircon_data_df = convert_AirconData(Aircon_Data)\n",
    "Aircon_data_df = Aircon_data_df[3194:]\n",
    "Sensor_readings_df = convert_sensorReadings(Sensor_readings)\n",
    "Sensor_readings_df = Sensor_readings_df.interpolate(method='linear')\n",
    "weather_readings_df = convert_weatherData(Weather_readings)\n",
    "\n",
    "# Merge Aircon data with Sensor readings using merge_asof\n",
    "merged_df = pd.merge_asof(Aircon_data_df, Sensor_readings_df, on='Datetime', direction='nearest')\n",
    "\n",
    "# Now, merge the Weather readings with the previous result using merge_asof\n",
    "merged_df = pd.merge_asof(merged_df, weather_readings_df, on='Datetime', direction='nearest')\n",
    "\n",
    "\n",
    "merged_df['total_energy'] = (\n",
    "    merged_df['Sensor_1_Energy'] +\n",
    "    merged_df['Sensor_3_Energy'] +\n",
    "    merged_df['Sensor_6_Energy']\n",
    ")\n",
    "\n",
    "merged_df['total_power'] = (\n",
    "    merged_df['Sensor_1_Power'] +\n",
    "    merged_df['Sensor_3_Power'] +\n",
    "    merged_df['Sensor_6_Power']\n",
    ")\n",
    "\n",
    "merged_df['total_current'] = (\n",
    "    merged_df['Sensor_1_Current'] +\n",
    "    merged_df['Sensor_3_Current'] +\n",
    "    merged_df['Sensor_6_Current']\n",
    ")\n",
    "\n",
    "temperature_col = [\n",
    "    col for col in merged_df.columns \n",
    "    if \"24e124\" in col.lower() and \"temperature\" in col.lower()\n",
    "]\n",
    "humidity_col = [\n",
    "    col for col in merged_df.columns \n",
    "    if \"24e124\" in col.lower() and \"humidity\" in col.lower()\n",
    "]\n",
    "co2_col = [\n",
    "    col for col in merged_df.columns \n",
    "    if \"24e124\" in col.lower() and \"co2\" in col.lower()\n",
    "]\n",
    "\n",
    "merged_df['avg_temperature'] = merged_df[temperature_col].mean(axis=1)\n",
    "merged_df['avg_humidity'] = merged_df[humidity_col].mean(axis=1)\n",
    "merged_df['avg_co2'] = merged_df[co2_col].mean(axis=1)\n",
    "\n",
    "merged_df['hour'] = pd.to_datetime(merged_df['Datetime']).dt.hour\n",
    "merged_df['Day_of_week'] = pd.to_datetime(merged_df['Datetime']).dt.dayofweek\n",
    "print(\"successful\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df641a8b-76ef-4b0c-9ac4-6a9d0d963e26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from hyperparam_tuning\\fanunit_LSTM_2\\tuner0.json\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "96                |96                |units_lstm\n",
      "0.01              |0.073             |l2_lstm\n",
      "False             |True              |return_sequences\n",
      "0.3               |0                 |dropout_lstm\n",
      "32                |32                |units_dense\n",
      "0.08              |0.079             |l2_dense\n",
      "0.001             |0.0001            |learning_rate\n",
      "\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1303, in mean_squared_error\n",
      "    return ops.mean(ops.square(y_true - y_pred), axis=-1)\n",
      "                               ~~~~~~~^~~~~~~~\n",
      "ValueError: Dimensions must be equal, but are 56 and 8 for '{{node compile_loss/mean_squared_error/sub}} = Sub[T=DT_FLOAT](data_2, functional_1/numerical_output_1/Add)' with input shapes: [?,56], [?,8].\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1303, in mean_squared_error\n    return ops.mean(ops.square(y_true - y_pred), axis=-1)\n                               ~~~~~~~^~~~~~~~\nValueError: Dimensions must be equal, but are 56 and 8 for '{{node compile_loss/mean_squared_error/sub}} = Sub[T=DT_FLOAT](data_2, functional_1/numerical_output_1/Add)' with input shapes: [?,56], [?,8].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 136\u001b[0m\n\u001b[0;32m    129\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[0;32m    130\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    131\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m    132\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    133\u001b[0m )\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Perform hyperparameter search\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m tuner\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m    137\u001b[0m     X_train, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_output\u001b[39m\u001b[38;5;124m'\u001b[39m: y_cat_train, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumerical_output\u001b[39m\u001b[38;5;124m'\u001b[39m: y_num_train},\n\u001b[0;32m    138\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m,\n\u001b[0;32m    139\u001b[0m     validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,\n\u001b[0;32m    140\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m    141\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stopping]\n\u001b[0;32m    142\u001b[0m )\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Get the best hyperparameters\u001b[39;00m\n\u001b[0;32m    145\u001b[0m best_hps \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_hyperparameters(num_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:339\u001b[0m, in \u001b[0;36mBaseTuner.on_trial_end\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_trial_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[0;32m    334\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mend_trial(trial)\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\oracle.py:108\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m     LOCKS[oracle]\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    107\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m thread_name\n\u001b[1;32m--> 108\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_acquire:\n\u001b[0;32m    110\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\oracle.py:588\u001b[0m, in \u001b[0;36mOracle.end_trial\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry(trial):\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_order\u001b[38;5;241m.\u001b[39mappend(trial\u001b[38;5;241m.\u001b[39mtrial_id)\n\u001b[1;32m--> 588\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_consecutive_failures()\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_trial(trial)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\oracle.py:545\u001b[0m, in \u001b[0;36mOracle._check_consecutive_failures\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    543\u001b[0m     consecutive_failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consecutive_failures \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials:\n\u001b[1;32m--> 545\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of consecutive failures exceeded the limit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    548\u001b[0m         \u001b[38;5;241m+\u001b[39m (trial\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    549\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\yy\\anaconda3\\envs\\yy_1\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1303, in mean_squared_error\n    return ops.mean(ops.square(y_true - y_pred), axis=-1)\n                               ~~~~~~~^~~~~~~~\nValueError: Dimensions must be equal, but are 56 and 8 for '{{node compile_loss/mean_squared_error/sub}} = Sub[T=DT_FLOAT](data_2, functional_1/numerical_output_1/Add)' with input shapes: [?,56], [?,8].\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# Input and categorical features\n",
    "input_features = [\n",
    "    'avg_temperature', 'avg_humidity', 'avg_co2',\n",
    "    'weather_temp', 'weather_humid', 'total_energy',\n",
    "    'total_power', 'total_current', 'hour', 'Day_of_week'\n",
    "]\n",
    "cat_features = ['weather_status']\n",
    "\n",
    "# Fan unit columns\n",
    "fan_unit_col = [col for col in merged_df.columns if \"fc_unit\" in col.lower()]\n",
    "\n",
    "# Split X and y\n",
    "X = merged_df[input_features + cat_features]\n",
    "y = merged_df[fan_unit_col]\n",
    "\n",
    "# Preprocessor for X\n",
    "preprocessor_X = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), input_features),\n",
    "        ('cat', OneHotEncoder(), cat_features)\n",
    "    ]\n",
    ")\n",
    "X_processed = preprocessor_X.fit_transform(X)\n",
    "\n",
    "# Preprocessor for y\n",
    "cat_cols = [col for col in fan_unit_col if \"Status\" in col or \"Mode\" in col]\n",
    "num_cols = [col for col in fan_unit_col if \"Set_Point\" in col]\n",
    "preprocessor_y = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), cat_cols),\n",
    "        ('num', StandardScaler(), num_cols)\n",
    "    ]\n",
    ")\n",
    "y_processed = preprocessor_y.fit_transform(y)\n",
    "\n",
    "# Ensure y_processed is dense\n",
    "if hasattr(y_processed, \"toarray\"):\n",
    "    y_processed = y_processed.toarray()\n",
    "\n",
    "# Separate categorical and numerical targets\n",
    "num_cat_outputs = len(cat_cols)  # Number of categorical output variables\n",
    "num_num_outputs = len(num_cols)  # Number of numerical output variables\n",
    "\n",
    "y_cat = y_processed[:, :num_cat_outputs] \n",
    "y_num = y_processed[:, num_cat_outputs:]  \n",
    "\n",
    "# Reshape X for LSTM\n",
    "X_processed = X_processed.reshape((X_processed.shape[0], 1, X_processed.shape[1]))\n",
    "\n",
    "# Split the data into train and test\n",
    "X_train, X_test, y_cat_train, y_cat_test, y_num_train, y_num_test = train_test_split(\n",
    "    X_processed, y_cat, y_num, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define the LSTM model-building function for KerasTuner\n",
    "def build_model(hp):\n",
    "    # Input layer\n",
    "    input_layer = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "    # LSTM layer\n",
    "    lstm = LSTM(\n",
    "        units=hp.Int('units_lstm', min_value=32, max_value=128, step=32),\n",
    "        activation='tanh',\n",
    "        recurrent_activation='sigmoid',\n",
    "        kernel_regularizer=l2(hp.Float('l2_lstm', 0.001, 0.1, step=0.001)),\n",
    "        input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "        return_sequences=hp.Boolean('return_sequences')\n",
    "    )(input_layer)\n",
    "    lstm = Dropout(rate=hp.Float('dropout_lstm', 0.0, 0.5, step=0.1))(lstm)\n",
    "\n",
    "    # Dense layer\n",
    "    dense = Dense(\n",
    "        units=hp.Int('units_dense', min_value=16, max_value=64, step=16),\n",
    "        activation='relu',\n",
    "        kernel_regularizer=l2(hp.Float('l2_dense', 0.001, 0.1, step=0.001))\n",
    "    )(lstm)\n",
    "\n",
    "    # Categorical output\n",
    "    categorical_output = Dense(num_cat_outputs, activation='softmax', name='categorical_output')(dense)\n",
    "\n",
    "    # Numerical output\n",
    "    numerical_output = Dense(num_num_outputs, activation='linear', name='numerical_output')(dense)\n",
    "\n",
    "    # Define the model with multiple outputs\n",
    "    model = Model(inputs=input_layer, outputs=[categorical_output, numerical_output])\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = Adam(learning_rate=hp.Choice('learning_rate', values=[1e-3, 1e-4]))\n",
    "\n",
    "    # Compile the model with different loss functions for each output\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss={\n",
    "            'categorical_output': 'categorical_crossentropy',  # For categorical\n",
    "            'numerical_output': 'mean_squared_error'  # For numerical \n",
    "        },\n",
    "        metrics={\n",
    "            'categorical_output': 'accuracy',\n",
    "            'numerical_output': 'mae'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize KerasTuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    directory='hyperparam_tuning',\n",
    "    project_name='fanunit_LSTM_2'\n",
    ")\n",
    "\n",
    "# Callback for early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Perform hyperparameter search\n",
    "tuner.search(\n",
    "    X_train, {'categorical_output': y_cat_train, 'numerical_output': y_num_train},\n",
    "    epochs=300,\n",
    "    validation_split=0.3,\n",
    "    batch_size=8,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_hps.values)\n",
    "\n",
    "# Build and train the model with best hyperparameters\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(\n",
    "    X_train, \n",
    "    {'categorical_output': y_cat_train, 'numerical_output': y_num_train},\n",
    "    validation_split=0.3,\n",
    "    epochs=300,\n",
    "    batch_size=8,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "best_model.save('models/LSTM_Fanunit_v2.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3f144c-86b0-48e6-aff7-9baa4ac72f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Or ignore specific warning types\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "# List of possible weather statuses\n",
    "weather_statuses = ['Clouds', 'Rain', 'Thunderstorm']\n",
    "\n",
    "# Relevant columns for input\n",
    "input_features = [\n",
    "    'avg_temperature', 'avg_humidity', 'avg_co2',\n",
    "    'weather_temp', 'weather_humid', 'total_energy', \n",
    "    'total_power', 'total_current', 'hour', 'Day_of_week'\n",
    "]\n",
    "categorical_features = ['weather_status']\n",
    "\n",
    "\n",
    "def generate_random_conditions():\n",
    "    \"\"\"Generate a dictionary of randomized conditions\"\"\"\n",
    "    return {\n",
    "        'ISO_formatted_datetime': datetime.now().isoformat(),\n",
    "        'avg_temperature': round(random.uniform(20, 30), 2),\n",
    "        'avg_humidity': round(random.uniform(30, 80), 2),\n",
    "        'avg_co2': round(random.uniform(350, 500), 2),\n",
    "        'weather_temp': round(random.uniform(22, 33), 2),\n",
    "        'weather_humid': round(random.uniform(40, 90), 2),\n",
    "        'total_current': round(random.uniform(0.5, 1.5), 2),\n",
    "        'total_energy': round(random.uniform(2000, 5000), 2),\n",
    "        'total_power': round(random.uniform(5, 15), 2),\n",
    "        'hour': random.randint(0, 23), \n",
    "        'Day_of_week': random.randint(0, 6),  \n",
    "        'weather_status': random.choice(weather_statuses)\n",
    "    }\n",
    "\n",
    "# Generate multiple random condition sets\n",
    "num_scenarios = 1\n",
    "scenario_results = []\n",
    "\n",
    "loaded_model = keras.models.load_model(\"models/LSTM_Fanunit_v1.keras\")\n",
    "\n",
    "for scenario in range(num_scenarios):\n",
    "    # Generate a random set of conditions\n",
    "    current_conditions = generate_random_conditions()\n",
    "    print(f\"\\nScenario {scenario + 1} Conditions:\")\n",
    "    for key, value in current_conditions.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Create a DataFrame with the current conditions\n",
    "    df = pd.DataFrame([current_conditions])\n",
    "    \n",
    "    # Preprocess\n",
    "    X_temp = preprocessor_X.transform(df[input_features + categorical_features])\n",
    "    X_temp = X_temp.reshape((X_temp.shape[0], 1, X_temp.shape[1]))\n",
    "    \n",
    "    # Predict\n",
    "    prediction = loaded_model.predict(X_temp)[0][0]\n",
    "    \n",
    "    # Print prediction\n",
    "    print(f\"{prediction}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ab2096-b0e4-4a95-be8e-d21003000115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
