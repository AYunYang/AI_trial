{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb5f46d8-57ff-48b2-8036-c7dd60f9994c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yy\\AppData\\Local\\Temp\\ipykernel_62224\\1082404539.py:256: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_data[occupancy_col_total_in] = merged_data[occupancy_col_total_in].fillna(method='bfill')\n",
      "C:\\Users\\yy\\AppData\\Local\\Temp\\ipykernel_62224\\1082404539.py:257: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_data[occupancy_col_total_out] = merged_data[occupancy_col_total_out].fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_data_created\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import time as clock\n",
    "\n",
    "start_time = clock.time()\n",
    "# Sensors_Data = pd.read_json('data/W512_readings.json')\n",
    "# Aircon_Data = pd.read_json('data/W512_aircon_status.json')\n",
    "# Weather_Data = pd.read_json('data/Weather_data.json')\n",
    "\n",
    "Sensors_Data = pd.read_json('../test/W512_readings1.json')\n",
    "Sensors_Data_1 = pd.read_json('../test/SPGG_readings1.json') # Since w512 don have outdoor sensor yet, we will use the outdoor sensor from spgg\n",
    "Aircon_Data = pd.read_json('../test/W512_aircon_status1.json')\n",
    "Weather_Data = pd.read_json('../test/Weather_data1.json')\n",
    "\n",
    "Aircon_rows = []\n",
    "\n",
    "for _, row in Aircon_Data.iterrows():\n",
    "    date = row['date']\n",
    "    time = row['time']\n",
    "    \n",
    "    flattened_row = {\n",
    "        \"date\": date,\n",
    "        \"time\": time\n",
    "    }\n",
    "    \n",
    "    fc_readings = row['FC_FullStatus_Readings']\n",
    "    if fc_readings and isinstance(fc_readings, dict):\n",
    "        for unit, data in fc_readings.items():\n",
    "            if any(data.get(\"Set_Point\", None) == 404.0 for data in fc_readings.values()):\n",
    "                continue\n",
    "            flattened_row[f\"{unit}_Status\"] = data.get(\"Status\", None)\n",
    "            flattened_row[f\"{unit}_Fan_Status\"] = data.get(\"Fan_Status\", None)\n",
    "            flattened_row[f\"{unit}_Set_Point\"] = data.get(\"Set_Point\", None)\n",
    "            flattened_row[f\"{unit}_Operation_Mode\"] = data.get(\"Operation_Mode\", None)\n",
    "    \n",
    "    Aircon_rows.append(flattened_row)\n",
    "\n",
    "Sensors_rows = []\n",
    "include_keys_1 = [\"24E124725E285123\", \"24E124725E331695\",\"24E124725E331744\",\n",
    "                      \"24E124725E332483\",\"24E124725E290348\",\"24E124725E331733\",\"24E124725E286745\",\"24E124725E332564\" # \"24E124136D316361\" is supposed to be outdoor but it is not outdoor yet\n",
    "                         \"24E124757E150866\",\"24E124757E150896\"]\n",
    "\n",
    "include_keys_2 = [\"Sensor_1\",\"Sensor_3\",\"Sensor_6\"]\n",
    "for _, row in Sensors_Data.iterrows():\n",
    "    invalid_input = False\n",
    "    \n",
    "    date = row['date']\n",
    "    time = row['time']\n",
    "    \n",
    "    flattened_row = {\n",
    "        \"date\": date,\n",
    "        \"time\": time\n",
    "    }\n",
    "    \n",
    "    \n",
    "    lorawan_readings = row['Lorawan_Readings']\n",
    "    \n",
    "    if isinstance(lorawan_readings, dict):\n",
    "        for unit, data in lorawan_readings.items():\n",
    "            if unit not in include_keys_1:\n",
    "                continue\n",
    "            if isinstance(data, dict):  # Ensure that each item in Lorawan_Readings is a dictionary\n",
    "                for key, value in data.items():\n",
    "                    \n",
    "                    flattened_row[f\"{unit}_{key}\"] = value\n",
    "            \n",
    "    energy_readings = row['Energy_Readings']\n",
    "    total_power = 0\n",
    "    total_energy = 0\n",
    "    invalid_input_power = False\n",
    "    invalid_input_energy = False\n",
    "    \n",
    "    if energy_readings and isinstance(energy_readings, dict):\n",
    "        for unit, data in energy_readings.items():\n",
    "            if unit not in include_keys_2:\n",
    "                continue\n",
    "            power = data.get('Power', None)\n",
    "            energy = data.get('Energy', None)\n",
    "            if power is None:\n",
    "                invalid_input_power = True\n",
    "            if energy is None:\n",
    "                invalid_input_energy = True\n",
    "            total_power += power\n",
    "            total_energy += energy\n",
    "        \n",
    "    if invalid_input_power:\n",
    "        total_power = None\n",
    "    if invalid_input_energy:\n",
    "        total_energy = None\n",
    "        \n",
    "    flattened_row[\"Total_Energy\"] = total_energy\n",
    "    flattened_row[\"Total_Power\"] = total_power\n",
    "    \n",
    "    Sensors_rows.append(flattened_row)\n",
    "\n",
    "Sensors_rows_1 = []\n",
    "outdoor_key = [\"24E124136D336145\"] # this is the id of the outdoor sensor from spgg\n",
    "\n",
    "for _, row in Sensors_Data_1.iterrows():\n",
    "    invalid_input = False\n",
    "    \n",
    "    date = row['date']\n",
    "    time = row['time']\n",
    "    \n",
    "    flattened_row = {\n",
    "        \"date\": date,\n",
    "        \"time\": time\n",
    "    }\n",
    "    \n",
    "    \n",
    "    lorawan_readings = row['Lorawan_Readings']\n",
    "    \n",
    "    if isinstance(lorawan_readings, dict):\n",
    "        for unit, data in lorawan_readings.items():\n",
    "            if unit not in outdoor_key:\n",
    "                continue\n",
    "            if isinstance(data, dict):  # Ensure that each item in Lorawan_Readings is a dictionary\n",
    "                for key, value in data.items():\n",
    "                    flattened_row[f\"{unit}_{key}\"] = value\n",
    "\n",
    "    Sensors_rows_1.append(flattened_row)\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "Weather_rows = []\n",
    "\n",
    "for _, row in Weather_Data.iterrows():\n",
    "    date = row['date']\n",
    "    time = row['time']\n",
    "    \n",
    "    flattened_row = {\n",
    "        \"date\": date,\n",
    "        \"time\": time\n",
    "    }\n",
    "    \n",
    "    flattened_row['weather_status']= row['result']['weather_status']\n",
    "    flattened_row['weather_temp']= row['result']['weather_temp']\n",
    "    flattened_row['weather_humidity']= row['result']['weather_humidity']\n",
    "    \n",
    "    Weather_rows.append(flattened_row)\n",
    "\n",
    "\n",
    "\n",
    "Aircon_Normalize_Data = pd.DataFrame(Aircon_rows)\n",
    "Sensors_Normalize_Data = pd.DataFrame(Sensors_rows)\n",
    "Sensors_Normalize_Data_1 = pd.DataFrame(Sensors_rows_1)\n",
    "Weather_Normalize_Data = pd.DataFrame(Weather_rows)\n",
    "# For Aircon_Normalize_Data\n",
    "Aircon_Normalize_Data['datetime_str'] = Aircon_Normalize_Data['date'].astype(str) + ' ' + Aircon_Normalize_Data['time']\n",
    "Aircon_Normalize_Data['datetime'] = Aircon_Normalize_Data['datetime_str'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d %I:%M:%S %p\"))\n",
    "Aircon_Normalize_Data['timestamp'] = Aircon_Normalize_Data['datetime'].apply(lambda x: int(x.timestamp()))\n",
    "\n",
    "# For Sensors_Normalize_Data\n",
    "Sensors_Normalize_Data['datetime_str'] = Sensors_Normalize_Data['date'].astype(str) + ' ' + Sensors_Normalize_Data['time']\n",
    "Sensors_Normalize_Data['datetime'] = Sensors_Normalize_Data['datetime_str'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d %I:%M:%S %p\"))\n",
    "Sensors_Normalize_Data['timestamp'] = Sensors_Normalize_Data['datetime'].apply(lambda x: int(x.timestamp()))\n",
    "\n",
    "# For Sensors_Normalize_Data\n",
    "Sensors_Normalize_Data_1['datetime_str'] = Sensors_Normalize_Data_1['date'].astype(str) + ' ' + Sensors_Normalize_Data_1['time']\n",
    "Sensors_Normalize_Data_1['datetime'] = Sensors_Normalize_Data_1['datetime_str'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d %I:%M:%S %p\"))\n",
    "Sensors_Normalize_Data_1['timestamp'] = Sensors_Normalize_Data_1['datetime'].apply(lambda x: int(x.timestamp()))\n",
    "\n",
    "# For Weather_Normalize_Data\n",
    "Weather_Normalize_Data['datetime_str'] = Weather_Normalize_Data['date'].astype(str) + ' ' + Weather_Normalize_Data['time']\n",
    "Weather_Normalize_Data['datetime'] = Weather_Normalize_Data['datetime_str'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d %I:%M:%S %p\"))\n",
    "Weather_Normalize_Data['timestamp'] = Weather_Normalize_Data['datetime'].apply(lambda x: int(x.timestamp()))\n",
    "\n",
    "merged_data = pd.merge_asof(\n",
    "    Aircon_Normalize_Data,  # Left DataFrame\n",
    "    Sensors_Normalize_Data,      # Right DataFrame\n",
    "    on='timestamp',   # Key column\n",
    "    direction='nearest'    # Match the nearest time\n",
    ")\n",
    "\n",
    "merged_data = pd.merge_asof(\n",
    "    merged_data,  # Left DataFrame\n",
    "    Sensors_Normalize_Data_1,      # Right DataFrame\n",
    "    on='timestamp',   # Key column\n",
    "    direction='nearest'    # Match the nearest time\n",
    ")\n",
    "#Since weather is inaccurate i will just not include weather in data analysis\n",
    "# merged_data = pd.merge_asof(\n",
    "#     merged_data,  # Left DataFrame\n",
    "#     Weather_Normalize_Data,      # Right DataFrame\n",
    "#     on='timestamp',   # Key column\n",
    "#     direction='nearest'    # Match the nearest time\n",
    "# )\n",
    "\n",
    "temperature_col = [\n",
    "    col for col in merged_data.columns \n",
    "    if \"temperature\" in col.lower()\n",
    "]\n",
    "humidity_col = [\n",
    "    col for col in merged_data.columns \n",
    "    if \"humidity\" in col.lower()\n",
    "]\n",
    "c02_col = [\n",
    "    col for col in merged_data.columns\n",
    "    if \"co2\" in col.lower()\n",
    "]\n",
    "\n",
    "outdoor_col = [\n",
    "    col for col in merged_data.columns \n",
    "    if \"24e124136d336145\" in col.lower()\n",
    "]\n",
    "\n",
    "occupancy_col_total_in = [\n",
    "    col for col in merged_data.columns\n",
    "    if \"total_in\" in col.lower()\n",
    "]\n",
    "\n",
    "occupancy_col_total_out = [\n",
    "    col for col in merged_data.columns\n",
    "    if \"total_out\" in col.lower()\n",
    "]\n",
    "\n",
    "def get_unit_columns(unit_number, columns):\n",
    "    return [col for col in columns if f\"FC_Unit_{unit_number}\" in col]\n",
    "\n",
    "aircon_units = len([\n",
    "    col for col in merged_data.columns\n",
    "    if \"FC_Unit_\" in col and \"_Status\" in col and \"Fan\" not in col\n",
    "])\n",
    "\n",
    "aircon_units_cols = {}\n",
    "\n",
    "for unit in range(1, aircon_units + 1):\n",
    "    aircon_units_cols[f'Unit_{unit}'] = get_unit_columns(unit, merged_data.columns)\n",
    "\n",
    "\n",
    "final_data = pd.DataFrame()\n",
    "final_data[\"timestamp\"] = merged_data[\"timestamp\"]\n",
    "\n",
    "final_data[\"temperature\"] = merged_data[temperature_col].apply(lambda x: round(x.mean(), 3), axis=1)\n",
    "final_data[\"humidity\"] = merged_data[humidity_col].apply(lambda x: round(x.mean(),3), axis=1)\n",
    "final_data[\"co2\"] = merged_data[c02_col].apply(lambda x: round(x.mean(),3), axis=1)\n",
    "\n",
    "final_data['power_consumption'] = merged_data['Total_Power']\n",
    "final_data['energy_consumption'] = merged_data['Total_Energy']\n",
    "\n",
    "final_data[\"outdoor_temperature\"] = merged_data[outdoor_col]['24E124136D336145_temperature'].ffill()\n",
    "final_data[\"outdoor_humidity\"] = merged_data[outdoor_col]['24E124136D336145_humidity'].ffill()\n",
    "\n",
    "# final_data[\"weather_status\"] = merged_data[\"weather_status\"]\n",
    "# final_data[\"weather_temp\"] = merged_data['weather_temp']\n",
    "# final_data[\"weather_humid\"] = merged_data['weather_humidity']\n",
    "\n",
    "\n",
    "merged_data[occupancy_col_total_in] = merged_data[occupancy_col_total_in].fillna(method='bfill')\n",
    "merged_data[occupancy_col_total_out] = merged_data[occupancy_col_total_out].fillna(method='bfill')\n",
    "\n",
    "final_data['occupancy'] = (\n",
    "    merged_data[occupancy_col_total_in].sum(axis=1) - merged_data[occupancy_col_total_out].sum(axis=1)\n",
    ")\n",
    "\n",
    "\n",
    "for unit, columns in aircon_units_cols.items():\n",
    "    for column in columns:\n",
    "        if 'set_point' in column:\n",
    "            final_data[column] = merged_data[column].replace(0, pd.NA).ffill()\n",
    "        else:\n",
    "            final_data[column] = merged_data[column].replace(\"ERROR\", pd.NA).ffill()\n",
    "\n",
    "final_data.dropna(inplace=True)\n",
    "print(\"final_data_created\")\n",
    "\n",
    "\n",
    "def getFCData(data, row_index):\n",
    "    settings = []\n",
    "    for i in range(1, aircon_units + 1):\n",
    "        settings.append(data[f\"FC_Unit_{i}_Status\"].iloc[row_index])\n",
    "        settings.append(data[f\"FC_Unit_{i}_Fan_Status\"].iloc[row_index])\n",
    "        settings.append(data[f\"FC_Unit_{i}_Set_Point\"].iloc[row_index])\n",
    "        settings.append(data[f\"FC_Unit_{i}_Operation_Mode\"].iloc[row_index])\n",
    "        \n",
    "    return settings\n",
    "\n",
    "def is_same_settings(data, curr_row_index, next_row_index):   \n",
    "    return True if (getFCData(data, curr_row_index) == getFCData(data, next_row_index)) else False\n",
    "\n",
    "\n",
    "def is_all_off(data, curr_row_index, check_for_off):\n",
    "    for i in range(1, aircon_units + 1):\n",
    "        if data[f\"FC_Unit_{i}_Status\"].iloc[curr_row_index] == \"ON\":\n",
    "            return not check_for_off\n",
    "        \n",
    "    return check_for_off\n",
    "\n",
    "def is_within_time_range(data, curr_row_index, next_row_index):\n",
    "    if abs(data[\"timestamp\"].iloc[next_row_index] - data[\"timestamp\"].iloc[curr_row_index]) < 1800:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# Reset index after filtering\n",
    "final_data.reset_index(drop=True, inplace=True)\n",
    "final_data.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "\n",
    "aircon_status_result = pd.DataFrame()\n",
    "total_final_rows = final_data.shape[0]\n",
    "Aircon_Normalize_Data = Aircon_Normalize_Data.drop(['date', 'time', 'datetime_str', 'datetime', 'timestamp'], axis=1)\n",
    "\n",
    "for i in range(total_final_rows - 1):\n",
    "    if is_all_off(final_data, i ,True):\n",
    "        continue\n",
    "    \n",
    "    curr_energy = final_data[\"energy_consumption\"].iloc[i]\n",
    "    next_energy = final_data[\"energy_consumption\"].iloc[i + 1]\n",
    "    \n",
    "    curr_temperature = final_data[\"temperature\"].iloc[i]\n",
    "    curr_humidity = final_data[\"humidity\"].iloc[i]\n",
    "    curr_outdoor_temp = final_data[\"outdoor_temperature\"].iloc[i]\n",
    "    curr_outdoor_humid = final_data[\"outdoor_humidity\"].iloc[i]\n",
    "\n",
    "    curr_co2 = final_data[\"co2\"].iloc[i]\n",
    "    \n",
    "    if is_same_settings(final_data, i , i + 1):   \n",
    "        diff = next_energy - curr_energy\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    temp_df = pd.DataFrame({\n",
    "        'energy_consumption': [diff],\n",
    "        'temperature': [curr_temperature],\n",
    "        'humidity': [curr_humidity],\n",
    "        'outdoor_temp':[curr_outdoor_temp],\n",
    "        'outdoor_humid':[curr_outdoor_humid],\n",
    "        \"co2\":[curr_co2]\n",
    "    })\n",
    "    for col in Aircon_Normalize_Data.columns:\n",
    "        temp_df[col] = final_data[col].iloc[i]\n",
    "    \n",
    "    aircon_status_result = pd.concat([aircon_status_result, temp_df], ignore_index=True)\n",
    "\n",
    "aircon_status_result = aircon_status_result[(aircon_status_result[\"energy_consumption\"] > 0.5 ) & (aircon_status_result[\"energy_consumption\"] < 50)]\n",
    "aircon_status_result.to_csv(\"updated_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad3836d1-342f-4243-b159-f6d92c63e4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'others': {'energy_consumption': 0.510000454545434}}, {'results': [{'time_taken_seconds': None, 'aircon_settings': [{'unit': 1, 'status': 'ON', 'fan_status': 'LOW', 'set_point': 22.8, 'operation_mode': 'COOL'}, {'unit': 2, 'status': 'ON', 'fan_status': 'MID', 'set_point': 19.0, 'operation_mode': 'COOL'}, {'unit': 3, 'status': 'ON', 'fan_status': 'LOW', 'set_point': 23.4, 'operation_mode': 'COOL'}, {'unit': 4, 'status': 'OFF', 'fan_status': 'OFF', 'set_point': 23.3, 'operation_mode': 'DRY'}, {'unit': 5, 'status': 'ON', 'fan_status': 'VERY LOW', 'set_point': 22.8, 'operation_mode': 'COOL'}, {'unit': 6, 'status': 'ON', 'fan_status': 'VERY LOW', 'set_point': 23.2, 'operation_mode': 'COOL'}, {'unit': 7, 'status': 'ON', 'fan_status': 'MID', 'set_point': 23.0, 'operation_mode': 'COOL'}, {'unit': 8, 'status': 'OFF', 'fan_status': 'OFF', 'set_point': 23.2, 'operation_mode': 'DRY'}]}]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yy\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=8.\n",
      "  warnings.warn(\n",
      "C:\\Users\\yy\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "# Read the CSV data\n",
    "df = aircon_status_result\n",
    "\n",
    "# Select features for clustering\n",
    "features = [\n",
    "    # 'energy_consumption', \n",
    "    'temperature', \n",
    "    'humidity', \n",
    "    'outdoor_temp', \n",
    "    'outdoor_humid',\n",
    "    'co2'\n",
    "]\n",
    "# Prepare the data\n",
    "X = df[features]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=20, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# df['cluster'] = kmeans.labels_\n",
    "# sns.pairplot(df, hue='cluster', vars=features, palette='viridis')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Assume we have a new input\n",
    "new_input = np.array([25, 66, 27.3, 60, 800])  # Complete the missing features\n",
    "centroids = kmeans.cluster_centers_\n",
    "new_input_scaled = scaler.transform([new_input])\n",
    "distances = pairwise_distances_argmin_min(new_input_scaled, centroids)\n",
    "\n",
    "# distances[0] is the index of the closest cluster\n",
    "\n",
    "filter_result = df[df[\"cluster\"] == distances[0][0]]\n",
    "filter_result.to_csv(\"filter_result.csv\")# Initialize the DataFrame for best settings\n",
    "fc_columns = [col for col in filter_result.columns if \"FC_Unit_\" in col]\n",
    "\n",
    "grouped = filter_result.groupby(fc_columns)[\"energy_consumption\"].mean().reset_index()\n",
    "grouped.to_csv(\"grouped.csv\")\n",
    "best_settings = grouped.sort_values(by=\"energy_consumption\", ascending=True)\n",
    "best_settings = best_settings.iloc[0]\n",
    "\n",
    "number_of_fc_unit = len([col for col in grouped.columns if \"FC_Unit_\" in col and \"_Status\" in col and \"Fan\" not in col])\n",
    "\n",
    "# Create a dictionary to format the result\n",
    "formatted_result = [\n",
    "        {\n",
    "            \"others\": {\n",
    "                \"energy_consumption\": best_settings[\"energy_consumption\"]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"results\": [\n",
    "                {\n",
    "                    \"time_taken_seconds\": None,  # or calculate if necessary\n",
    "                    \"aircon_settings\": [\n",
    "                        {\n",
    "                            \"unit\": idx + 1,\n",
    "                            \"status\": best_settings[f\"FC_Unit_{idx+1}_Status\"],\n",
    "                            \"fan_status\": best_settings[f\"FC_Unit_{idx+1}_Fan_Status\"],\n",
    "                            \"set_point\": best_settings[f\"FC_Unit_{idx+1}_Set_Point\"],\n",
    "                            \"operation_mode\": best_settings[f\"FC_Unit_{idx+1}_Operation_Mode\"]\n",
    "                        }\n",
    "                        for idx in range(number_of_fc_unit)  # Adjust range according to the number of units\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }]\n",
    "\n",
    "# Print the formatted result\n",
    "print(formatted_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e2bf6fe-e323-4150-9a47-1f80aebfd80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FC_Unit_1_Status FC_Unit_2_Status FC_Unit_3_Status FC_Unit_4_Status  \\\n",
      "0               ON               ON               ON              OFF   \n",
      "1               ON               ON               ON               ON   \n",
      "\n",
      "  FC_Unit_5_Status FC_Unit_6_Status FC_Unit_7_Status FC_Unit_8_Status  \\\n",
      "0              OFF              OFF               ON               ON   \n",
      "1               ON               ON               ON               ON   \n",
      "\n",
      "   energy_consumption  \n",
      "0            0.985000  \n",
      "1            1.245263  \n"
     ]
    }
   ],
   "source": [
    "best_settings = grouped.sort_values(by=\"energy_consumption\", ascending=True)\n",
    "print(best_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba2a90b-d1c8-4b8d-84f5-e72c45a37020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
